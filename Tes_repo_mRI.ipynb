{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP2uQpIJosyyH/5DWuiPrO3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/figaz123/mRI/blob/main/Tes_repo_mRI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuVjB5dxzMcN",
        "outputId": "d3a79d35-d11c-4cbb-fd2e-bd7595460e21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/mRI\")"
      ],
      "metadata": {
        "id": "DH8wwF8Vz0Fb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip3 install virtualenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsisW3Zh0KT4",
        "outputId": "f11541a2-1014-4ffb-b3c1-0de999b7d49d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.26.3-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv)\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.15.4)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (4.2.2)\n",
            "Downloading virtualenv-20.26.3-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: distlib, virtualenv\n",
            "Successfully installed distlib-0.3.8 virtualenv-20.26.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # # !mkdir venv\n",
        "# !virtualenv '/content/drive/MyDrive/mRI/venv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0VBiGxV0Omd",
        "outputId": "c0cb57ed-93da-475b-be3d-6d63dc1e6e18"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created virtual environment CPython3.10.12.final.0-64 in 32252ms\n",
            "  creator CPython3Posix(dest=/content/drive/MyDrive/mRI/venv, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==24.1, setuptools==70.1.0, wheel==0.43.0\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !source /content/drive/MyDrive/mRI/venv/bin/activate"
      ],
      "metadata": {
        "id": "xHHHCY_u0UyD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !source /content/venv/bin/activate; pip3 list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEzF8gPG06io",
        "outputId": "dbe91244-797a-42f9-93ca-e7700c7d2b4e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: /content/venv/bin/activate: No such file or directory\n",
            "Package                          Version\n",
            "-------------------------------- ---------------------\n",
            "absl-py                          1.4.0\n",
            "accelerate                       0.32.1\n",
            "aiohttp                          3.9.5\n",
            "aiosignal                        1.3.1\n",
            "alabaster                        0.7.16\n",
            "albucore                         0.0.12\n",
            "albumentations                   1.4.12\n",
            "altair                           4.2.2\n",
            "annotated-types                  0.7.0\n",
            "anyio                            3.7.1\n",
            "argon2-cffi                      23.1.0\n",
            "argon2-cffi-bindings             21.2.0\n",
            "array_record                     0.5.1\n",
            "arviz                            0.18.0\n",
            "asn1crypto                       1.5.1\n",
            "astropy                          6.1.2\n",
            "astropy-iers-data                0.2024.7.29.0.32.7\n",
            "astunparse                       1.6.3\n",
            "async-timeout                    4.0.3\n",
            "atpublic                         4.1.0\n",
            "attrs                            23.2.0\n",
            "audioread                        3.0.1\n",
            "autograd                         1.6.2\n",
            "Babel                            2.15.0\n",
            "backcall                         0.2.0\n",
            "beautifulsoup4                   4.12.3\n",
            "bidict                           0.23.1\n",
            "bigframes                        1.11.1\n",
            "bleach                           6.1.0\n",
            "blinker                          1.4\n",
            "blis                             0.7.11\n",
            "blosc2                           2.0.0\n",
            "bokeh                            3.4.3\n",
            "bqplot                           0.12.43\n",
            "branca                           0.7.2\n",
            "build                            1.2.1\n",
            "CacheControl                     0.14.0\n",
            "cachetools                       5.4.0\n",
            "catalogue                        2.0.10\n",
            "certifi                          2024.7.4\n",
            "cffi                             1.16.0\n",
            "chardet                          5.2.0\n",
            "charset-normalizer               3.3.2\n",
            "chex                             0.1.86\n",
            "clarabel                         0.9.0\n",
            "click                            8.1.7\n",
            "click-plugins                    1.1.1\n",
            "cligj                            0.7.2\n",
            "cloudpathlib                     0.18.1\n",
            "cloudpickle                      2.2.1\n",
            "cmake                            3.30.1\n",
            "cmdstanpy                        1.2.4\n",
            "colorcet                         3.1.0\n",
            "colorlover                       0.3.0\n",
            "colour                           0.1.5\n",
            "community                        1.0.0b1\n",
            "confection                       0.1.5\n",
            "cons                             0.4.6\n",
            "contextlib2                      21.6.0\n",
            "contourpy                        1.2.1\n",
            "cryptography                     42.0.8\n",
            "cuda-python                      12.2.1\n",
            "cudf-cu12                        24.4.1\n",
            "cufflinks                        0.17.3\n",
            "cupy-cuda12x                     12.2.0\n",
            "cvxopt                           1.3.2\n",
            "cvxpy                            1.5.2\n",
            "cycler                           0.12.1\n",
            "cymem                            2.0.8\n",
            "Cython                           3.0.10\n",
            "dask                             2024.7.1\n",
            "datascience                      0.17.6\n",
            "db-dtypes                        1.2.0\n",
            "dbus-python                      1.2.18\n",
            "debugpy                          1.6.6\n",
            "decorator                        4.4.2\n",
            "defusedxml                       0.7.1\n",
            "distlib                          0.3.8\n",
            "distributed                      2024.7.1\n",
            "distro                           1.7.0\n",
            "dlib                             19.24.2\n",
            "dm-tree                          0.1.8\n",
            "docstring_parser                 0.16\n",
            "docutils                         0.18.1\n",
            "dopamine_rl                      4.0.9\n",
            "duckdb                           0.10.3\n",
            "earthengine-api                  0.1.414\n",
            "easydict                         1.13\n",
            "ecos                             2.0.14\n",
            "editdistance                     0.8.1\n",
            "eerepr                           0.0.4\n",
            "en-core-web-sm                   3.7.1\n",
            "entrypoints                      0.4\n",
            "et-xmlfile                       1.1.0\n",
            "etils                            1.7.0\n",
            "etuples                          0.3.9\n",
            "eval_type_backport               0.2.0\n",
            "exceptiongroup                   1.2.2\n",
            "fastai                           2.7.15\n",
            "fastcore                         1.5.55\n",
            "fastdownload                     0.0.7\n",
            "fastjsonschema                   2.20.0\n",
            "fastprogress                     1.0.3\n",
            "fastrlock                        0.8.2\n",
            "filelock                         3.15.4\n",
            "fiona                            1.9.6\n",
            "firebase-admin                   6.5.0\n",
            "Flask                            2.2.5\n",
            "flatbuffers                      24.3.25\n",
            "flax                             0.8.4\n",
            "folium                           0.17.0\n",
            "fonttools                        4.53.1\n",
            "frozendict                       2.4.4\n",
            "frozenlist                       1.4.1\n",
            "fsspec                           2024.6.1\n",
            "future                           1.0.0\n",
            "gast                             0.6.0\n",
            "gcsfs                            2024.6.1\n",
            "GDAL                             3.6.4\n",
            "gdown                            5.1.0\n",
            "geemap                           0.33.1\n",
            "gensim                           4.3.3\n",
            "geocoder                         1.38.1\n",
            "geographiclib                    2.0\n",
            "geopandas                        0.14.4\n",
            "geopy                            2.4.1\n",
            "gin-config                       0.5.0\n",
            "glob2                            0.7\n",
            "google                           2.0.3\n",
            "google-ai-generativelanguage     0.6.6\n",
            "google-api-core                  2.19.1\n",
            "google-api-python-client         2.137.0\n",
            "google-auth                      2.27.0\n",
            "google-auth-httplib2             0.2.0\n",
            "google-auth-oauthlib             1.2.1\n",
            "google-cloud-aiplatform          1.59.0\n",
            "google-cloud-bigquery            3.25.0\n",
            "google-cloud-bigquery-connection 1.15.4\n",
            "google-cloud-bigquery-storage    2.25.0\n",
            "google-cloud-bigtable            2.25.0\n",
            "google-cloud-core                2.4.1\n",
            "google-cloud-datastore           2.19.0\n",
            "google-cloud-firestore           2.16.1\n",
            "google-cloud-functions           1.16.4\n",
            "google-cloud-iam                 2.15.1\n",
            "google-cloud-language            2.13.4\n",
            "google-cloud-pubsub              2.23.0\n",
            "google-cloud-resource-manager    1.12.4\n",
            "google-cloud-storage             2.8.0\n",
            "google-cloud-translate           3.15.4\n",
            "google-colab                     1.0.0\n",
            "google-crc32c                    1.5.0\n",
            "google-generativeai              0.7.2\n",
            "google-pasta                     0.2.0\n",
            "google-resumable-media           2.7.1\n",
            "googleapis-common-protos         1.63.2\n",
            "googledrivedownloader            0.4\n",
            "graphviz                         0.20.3\n",
            "greenlet                         3.0.3\n",
            "grpc-google-iam-v1               0.13.1\n",
            "grpcio                           1.64.1\n",
            "grpcio-status                    1.48.2\n",
            "gspread                          6.0.2\n",
            "gspread-dataframe                3.3.1\n",
            "gym                              0.25.2\n",
            "gym-notices                      0.0.8\n",
            "h5netcdf                         1.3.0\n",
            "h5py                             3.11.0\n",
            "holidays                         0.53\n",
            "holoviews                        1.18.3\n",
            "html5lib                         1.1\n",
            "httpimport                       1.3.1\n",
            "httplib2                         0.22.0\n",
            "huggingface-hub                  0.23.5\n",
            "humanize                         4.10.0\n",
            "hyperopt                         0.2.7\n",
            "ibis-framework                   8.0.0\n",
            "idna                             3.7\n",
            "imageio                          2.34.2\n",
            "imageio-ffmpeg                   0.5.1\n",
            "imagesize                        1.4.1\n",
            "imbalanced-learn                 0.12.3\n",
            "imgaug                           0.4.0\n",
            "immutabledict                    4.2.0\n",
            "importlib_metadata               8.2.0\n",
            "importlib_resources              6.4.0\n",
            "imutils                          0.5.4\n",
            "inflect                          7.3.1\n",
            "iniconfig                        2.0.0\n",
            "intel-cmplr-lib-ur               2024.2.0\n",
            "intel-openmp                     2024.2.0\n",
            "ipyevents                        2.0.2\n",
            "ipyfilechooser                   0.6.0\n",
            "ipykernel                        5.5.6\n",
            "ipyleaflet                       0.18.2\n",
            "ipyparallel                      8.8.0\n",
            "ipython                          7.34.0\n",
            "ipython-genutils                 0.2.0\n",
            "ipython-sql                      0.5.0\n",
            "ipytree                          0.2.2\n",
            "ipywidgets                       7.7.1\n",
            "itsdangerous                     2.2.0\n",
            "jax                              0.4.26\n",
            "jaxlib                           0.4.26+cuda12.cudnn89\n",
            "jeepney                          0.7.1\n",
            "jellyfish                        1.1.0\n",
            "jieba                            0.42.1\n",
            "Jinja2                           3.1.4\n",
            "joblib                           1.4.2\n",
            "jsonpickle                       3.2.2\n",
            "jsonschema                       4.23.0\n",
            "jsonschema-specifications        2023.12.1\n",
            "jupyter-client                   6.1.12\n",
            "jupyter-console                  6.1.0\n",
            "jupyter_core                     5.7.2\n",
            "jupyter-server                   1.24.0\n",
            "jupyterlab_pygments              0.3.0\n",
            "jupyterlab_widgets               3.0.11\n",
            "kaggle                           1.6.17\n",
            "kagglehub                        0.2.8\n",
            "keras                            3.4.1\n",
            "keyring                          23.5.0\n",
            "kiwisolver                       1.4.5\n",
            "langcodes                        3.4.0\n",
            "language_data                    1.2.0\n",
            "launchpadlib                     1.10.16\n",
            "lazr.restfulclient               0.14.4\n",
            "lazr.uri                         1.0.6\n",
            "lazy_loader                      0.4\n",
            "libclang                         18.1.1\n",
            "librosa                          0.10.2.post1\n",
            "lightgbm                         4.4.0\n",
            "linkify-it-py                    2.0.3\n",
            "llvmlite                         0.43.0\n",
            "locket                           1.0.0\n",
            "logical-unification              0.4.6\n",
            "lxml                             4.9.4\n",
            "malloy                           2024.1089\n",
            "marisa-trie                      1.2.0\n",
            "Markdown                         3.6\n",
            "markdown-it-py                   3.0.0\n",
            "MarkupSafe                       2.1.5\n",
            "matplotlib                       3.7.1\n",
            "matplotlib-inline                0.1.7\n",
            "matplotlib-venn                  0.11.10\n",
            "mdit-py-plugins                  0.4.1\n",
            "mdurl                            0.1.2\n",
            "miniKanren                       1.0.3\n",
            "missingno                        0.5.2\n",
            "mistune                          0.8.4\n",
            "mizani                           0.9.3\n",
            "mkl                              2024.2.0\n",
            "ml-dtypes                        0.4.0\n",
            "mlxtend                          0.23.1\n",
            "more-itertools                   10.3.0\n",
            "moviepy                          1.0.3\n",
            "mpmath                           1.3.0\n",
            "msgpack                          1.0.8\n",
            "multidict                        6.0.5\n",
            "multipledispatch                 1.0.0\n",
            "multitasking                     0.0.11\n",
            "murmurhash                       1.0.10\n",
            "music21                          9.1.0\n",
            "namex                            0.0.8\n",
            "natsort                          8.4.0\n",
            "nbclassic                        1.1.0\n",
            "nbclient                         0.10.0\n",
            "nbconvert                        6.5.4\n",
            "nbformat                         5.10.4\n",
            "nest-asyncio                     1.6.0\n",
            "networkx                         3.3\n",
            "nibabel                          5.0.1\n",
            "nltk                             3.8.1\n",
            "notebook                         6.5.5\n",
            "notebook_shim                    0.2.4\n",
            "numba                            0.60.0\n",
            "numexpr                          2.10.1\n",
            "numpy                            1.26.4\n",
            "nvtx                             0.2.10\n",
            "oauth2client                     4.1.3\n",
            "oauthlib                         3.2.2\n",
            "opencv-contrib-python            4.10.0.84\n",
            "opencv-python                    4.10.0.84\n",
            "opencv-python-headless           4.10.0.84\n",
            "openpyxl                         3.1.5\n",
            "opt-einsum                       3.3.0\n",
            "optax                            0.2.2\n",
            "optree                           0.12.1\n",
            "orbax-checkpoint                 0.5.23\n",
            "osqp                             0.6.7.post0\n",
            "packaging                        24.1\n",
            "pandas                           2.1.4\n",
            "pandas-datareader                0.10.0\n",
            "pandas-gbq                       0.19.2\n",
            "pandas-stubs                     2.1.4.231227\n",
            "pandocfilters                    1.5.1\n",
            "panel                            1.4.4\n",
            "param                            2.1.1\n",
            "parso                            0.8.4\n",
            "parsy                            2.1\n",
            "partd                            1.4.2\n",
            "pathlib                          1.0.1\n",
            "patsy                            0.5.6\n",
            "peewee                           3.17.6\n",
            "pexpect                          4.9.0\n",
            "pickleshare                      0.7.5\n",
            "Pillow                           9.4.0\n",
            "pip                              24.1.2\n",
            "pip-tools                        7.4.1\n",
            "platformdirs                     4.2.2\n",
            "plotly                           5.15.0\n",
            "plotnine                         0.12.4\n",
            "pluggy                           1.5.0\n",
            "polars                           0.20.2\n",
            "pooch                            1.8.2\n",
            "portpicker                       1.5.2\n",
            "prefetch_generator               1.0.3\n",
            "preshed                          3.0.9\n",
            "prettytable                      3.10.2\n",
            "proglog                          0.1.10\n",
            "progressbar2                     4.2.0\n",
            "prometheus_client                0.20.0\n",
            "promise                          2.3\n",
            "prompt_toolkit                   3.0.47\n",
            "prophet                          1.1.5\n",
            "proto-plus                       1.24.0\n",
            "protobuf                         3.20.3\n",
            "psutil                           5.9.5\n",
            "psycopg2                         2.9.9\n",
            "ptyprocess                       0.7.0\n",
            "py-cpuinfo                       9.0.0\n",
            "py4j                             0.10.9.7\n",
            "pyarrow                          14.0.2\n",
            "pyarrow-hotfix                   0.6\n",
            "pyasn1                           0.6.0\n",
            "pyasn1_modules                   0.4.0\n",
            "pycocotools                      2.0.8\n",
            "pycparser                        2.22\n",
            "pydantic                         2.8.2\n",
            "pydantic_core                    2.20.1\n",
            "pydata-google-auth               1.8.2\n",
            "pydot                            1.4.2\n",
            "pydot-ng                         2.0.0\n",
            "pydotplus                        2.0.2\n",
            "PyDrive                          1.3.1\n",
            "PyDrive2                         1.6.3\n",
            "pyerfa                           2.0.1.4\n",
            "pygame                           2.6.0\n",
            "Pygments                         2.16.1\n",
            "PyGObject                        3.42.1\n",
            "PyJWT                            2.8.0\n",
            "pymc                             5.10.4\n",
            "pymystem3                        0.2.0\n",
            "pynvjitlink-cu12                 0.3.0\n",
            "PyOpenGL                         3.1.7\n",
            "pyOpenSSL                        24.2.1\n",
            "pyparsing                        3.1.2\n",
            "pyperclip                        1.9.0\n",
            "pyproj                           3.6.1\n",
            "pyproject_hooks                  1.1.0\n",
            "pyshp                            2.3.1\n",
            "PySocks                          1.7.1\n",
            "pytensor                         2.18.6\n",
            "pytest                           7.4.4\n",
            "python-apt                       2.4.0\n",
            "python-box                       7.2.0\n",
            "python-dateutil                  2.8.2\n",
            "python-louvain                   0.16\n",
            "python-slugify                   8.0.4\n",
            "python-utils                     3.8.2\n",
            "pytz                             2024.1\n",
            "pyviz_comms                      3.0.2\n",
            "PyYAML                           6.0.1\n",
            "pyzmq                            24.0.1\n",
            "qdldl                            0.1.7.post4\n",
            "ratelim                          0.1.6\n",
            "referencing                      0.35.1\n",
            "regex                            2024.5.15\n",
            "requests                         2.31.0\n",
            "requests-oauthlib                1.3.1\n",
            "requirements-parser              0.9.0\n",
            "rich                             13.7.1\n",
            "rmm-cu12                         24.4.0\n",
            "rpds-py                          0.19.1\n",
            "rpy2                             3.4.2\n",
            "rsa                              4.9\n",
            "safetensors                      0.4.3\n",
            "scikit-image                     0.23.2\n",
            "scikit-learn                     1.3.2\n",
            "scipy                            1.13.1\n",
            "scooby                           0.10.0\n",
            "scs                              3.2.6\n",
            "seaborn                          0.13.1\n",
            "SecretStorage                    3.3.1\n",
            "Send2Trash                       1.8.3\n",
            "sentencepiece                    0.1.99\n",
            "setuptools                       71.0.4\n",
            "shapely                          2.0.5\n",
            "shellingham                      1.5.4\n",
            "simple_parsing                   0.1.5\n",
            "six                              1.16.0\n",
            "sklearn-pandas                   2.2.0\n",
            "smart-open                       7.0.4\n",
            "sniffio                          1.3.1\n",
            "snowballstemmer                  2.2.0\n",
            "snowflake-connector-python       3.12.0\n",
            "sortedcontainers                 2.4.0\n",
            "soundfile                        0.12.1\n",
            "soupsieve                        2.5\n",
            "soxr                             0.4.0\n",
            "spacy                            3.7.5\n",
            "spacy-legacy                     3.0.12\n",
            "spacy-loggers                    1.0.5\n",
            "Sphinx                           5.0.2\n",
            "sphinxcontrib-applehelp          2.0.0\n",
            "sphinxcontrib-devhelp            2.0.0\n",
            "sphinxcontrib-htmlhelp           2.1.0\n",
            "sphinxcontrib-jsmath             1.0.1\n",
            "sphinxcontrib-qthelp             2.0.0\n",
            "sphinxcontrib-serializinghtml    2.0.0\n",
            "SQLAlchemy                       2.0.31\n",
            "sqlglot                          20.11.0\n",
            "sqlparse                         0.5.1\n",
            "srsly                            2.4.8\n",
            "stanio                           0.5.1\n",
            "statsmodels                      0.14.2\n",
            "StrEnum                          0.4.15\n",
            "sympy                            1.13.1\n",
            "tables                           3.8.0\n",
            "tabulate                         0.9.0\n",
            "tbb                              2021.13.0\n",
            "tblib                            3.0.0\n",
            "tenacity                         9.0.0\n",
            "tensorboard                      2.17.0\n",
            "tensorboard-data-server          0.7.2\n",
            "tensorflow                       2.17.0\n",
            "tensorflow-datasets              4.9.6\n",
            "tensorflow-hub                   0.16.1\n",
            "tensorflow-io-gcs-filesystem     0.37.1\n",
            "tensorflow-metadata              1.15.0\n",
            "tensorflow-probability           0.24.0\n",
            "tensorstore                      0.1.63\n",
            "termcolor                        2.4.0\n",
            "terminado                        0.18.1\n",
            "text-unidecode                   1.3\n",
            "textblob                         0.17.1\n",
            "tf_keras                         2.17.0\n",
            "tf-slim                          1.1.0\n",
            "thinc                            8.2.5\n",
            "threadpoolctl                    3.5.0\n",
            "tifffile                         2024.7.24\n",
            "tinycss2                         1.3.0\n",
            "tokenizers                       0.19.1\n",
            "toml                             0.10.2\n",
            "tomli                            2.0.1\n",
            "tomlkit                          0.13.0\n",
            "toolz                            0.12.1\n",
            "torch                            2.3.1+cu121\n",
            "torchaudio                       2.3.1+cu121\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.18.0\n",
            "torchvision                      0.18.1+cu121\n",
            "tornado                          6.3.3\n",
            "tqdm                             4.66.4\n",
            "traitlets                        5.7.1\n",
            "traittypes                       0.2.1\n",
            "transformers                     4.42.4\n",
            "triton                           2.3.1\n",
            "tweepy                           4.14.0\n",
            "typeguard                        4.3.0\n",
            "typer                            0.12.3\n",
            "types-pytz                       2024.1.0.20240417\n",
            "types-setuptools                 71.1.0.20240726\n",
            "typing_extensions                4.12.2\n",
            "tzdata                           2024.1\n",
            "tzlocal                          5.2\n",
            "uc-micro-py                      1.0.3\n",
            "uritemplate                      4.1.1\n",
            "urllib3                          2.0.7\n",
            "vega-datasets                    0.9.0\n",
            "virtualenv                       20.26.3\n",
            "wadllib                          1.3.6\n",
            "wasabi                           1.1.3\n",
            "wcwidth                          0.2.13\n",
            "weasel                           0.4.1\n",
            "webcolors                        24.6.0\n",
            "webencodings                     0.5.1\n",
            "websocket-client                 1.8.0\n",
            "Werkzeug                         3.0.3\n",
            "wheel                            0.43.0\n",
            "widgetsnbextension               3.6.8\n",
            "wordcloud                        1.9.3\n",
            "wrapt                            1.16.0\n",
            "xarray                           2024.6.0\n",
            "xarray-einstats                  0.7.0\n",
            "xgboost                          2.1.0\n",
            "xlrd                             2.0.1\n",
            "xyzservices                      2024.6.0\n",
            "yarl                             1.9.4\n",
            "yellowbrick                      1.5\n",
            "yfinance                         0.2.41\n",
            "zict                             3.0.0\n",
            "zipp                             3.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip3 install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46aKkdoU076t",
        "outputId": "f0d63360-9f17-4ad4-e266-cead18d0070f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ECywrHi2BbT",
        "outputId": "1f42ebb1-03df-43ea-ae8f-f167c1fe1f8d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.git', 'action_localization', 'README.md', '.gitignore', 'LICENSE', 'venv']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/mRI/action_localization')"
      ],
      "metadata": {
        "id": "RLL-o8N82CKb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvnjcq2p2LfW",
        "outputId": "f26ea8bb-32cc-451e-cbf3-98507e894d70"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tools',\n",
              " 'exp_configs',\n",
              " 'data',\n",
              " 'libs',\n",
              " 'configs',\n",
              " 'ckpt',\n",
              " 'README_ActionFormer.md',\n",
              " 'eval.py',\n",
              " 'README.md',\n",
              " 'train.py',\n",
              " 'FAQ.md',\n",
              " 'INSTALL.md',\n",
              " 'LICENSE',\n",
              " 'teaser.jpg',\n",
              " 'nms_1d_cpu.egg-info',\n",
              " 'build']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch==1.11\n",
        "# !pip3 install numpy==1.11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3vIw-LY2SCG",
        "outputId": "76f9f963-8334-4ccd-b01d-41ff04cb8ffa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.11\n",
            "  Downloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11) (4.12.2)\n",
            "Downloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.1+cu121\n",
            "    Uninstalling torch-2.3.1+cu121:\n",
            "      Successfully uninstalled torch-2.3.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 1.11.0 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 1.11.0 which is incompatible.\n",
            "torchvision 0.18.1+cu121 requires torch==2.3.1, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.11.0\n",
            "Collecting numpy==1.11\n",
            "  Downloading numpy-1.11.0.zip (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: numpy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for numpy (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for numpy\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for numpy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py clean\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[31m  ERROR: Failed cleaning build dir for numpy\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build numpy\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (numpy)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/drive/MyDrive/mRI/action_localization/libs/utils/setup.py\" install --user"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVU-LPZf2NHa",
        "outputId": "a29ac46d-2339-453b-a22a-2352dc8a76e8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing nms_1d_cpu.egg-info/PKG-INFO\n",
            "writing dependency_links to nms_1d_cpu.egg-info/dependency_links.txt\n",
            "writing top-level names to nms_1d_cpu.egg-info/top_level.txt\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:387: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest file 'nms_1d_cpu.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'nms_1d_cpu.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "building 'nms_1d_cpu' extension\n",
            "creating build/temp.linux-x86_64-cpython-310/content\n",
            "creating build/temp.linux-x86_64-cpython-310/content/drive\n",
            "creating build/temp.linux-x86_64-cpython-310/content/drive/MyDrive\n",
            "creating build/temp.linux-x86_64-cpython-310/content/drive/MyDrive/mRI\n",
            "creating build/temp.linux-x86_64-cpython-310/content/drive/MyDrive/mRI/action_localization\n",
            "creating build/temp.linux-x86_64-cpython-310/content/drive/MyDrive/mRI/action_localization/libs\n",
            "creating build/temp.linux-x86_64-cpython-310/content/drive/MyDrive/mRI/action_localization/libs/utils\n",
            "creating build/temp.linux-x86_64-cpython-310/content/drive/MyDrive/mRI/action_localization/libs/utils/csrc\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/include/python3.10 -c /content/drive/MyDrive/mRI/action_localization/libs/utils/csrc/nms_cpu.cpp -o build/temp.linux-x86_64-cpython-310/content/drive/MyDrive/mRI/action_localization/libs/utils/csrc/nms_cpu.o -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=nms_1d_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/content/drive/MyDrive/mRI/action_localization/libs/utils/csrc/nms_cpu.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-310/nms_1d_cpu.cpython-310-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-cpython-310/nms_1d_cpu.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for nms_1d_cpu.cpython-310-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nms_1d_cpu.py to nms_1d_cpu.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying nms_1d_cpu.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying nms_1d_cpu.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying nms_1d_cpu.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying nms_1d_cpu.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.nms_1d_cpu.cpython-310: module references __file__\n",
            "creating dist\n",
            "creating 'dist/nms_1d_cpu-0.0.0-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing nms_1d_cpu-0.0.0-py3.10-linux-x86_64.egg\n",
            "creating /root/.local/lib/python3.10/site-packages/nms_1d_cpu-0.0.0-py3.10-linux-x86_64.egg\n",
            "Extracting nms_1d_cpu-0.0.0-py3.10-linux-x86_64.egg to /root/.local/lib/python3.10/site-packages\n",
            "Adding nms-1d-cpu 0.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /root/.local/lib/python3.10/site-packages/nms_1d_cpu-0.0.0-py3.10-linux-x86_64.egg\n",
            "Processing dependencies for nms-1d-cpu==0.0.0\n",
            "Finished processing dependencies for nms-1d-cpu==0.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/MyDrive/mRI/action_localization/tools/gen_exps.py\" \"/content/drive/MyDrive/mRI/action_localization/configs/ref_cfg.yaml\" \"/content/drive/MyDrive/mRI/action_localization/configs/exp_cfg.yaml\""
      ],
      "metadata": {
        "id": "VQOgZHHI3KqV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !sh /content/drive/MyDrive/mRI/action_localization/exp_configs/run_all_exps.sh"
      ],
      "metadata": {
        "id": "EvLRtBPA535K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/drive/MyDrive/mRI/action_localization/train.py\" \"/content/drive/MyDrive/mRI/action_localization/exp_configs/rgb_s1_p1.yaml\" --output test -p 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP34K0d560Jq",
        "outputId": "e54765e6-d708-40f7-fd3c-04ede8b4281d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dataset': {'crop_ratio': [0.9, 1.0],\n",
            "             'default_fps': 50,\n",
            "             'downsample_rate': 25,\n",
            "             'feat_folder': '/content/drive/MyDrive/mRI/action_localization/data/pose_features',\n",
            "             'feat_stride': 1,\n",
            "             'file_ext': '.npz',\n",
            "             'file_prefix': None,\n",
            "             'force_upsampling': False,\n",
            "             'input_dim': 51,\n",
            "             'json_file': '/content/drive/MyDrive/mRI/action_localization/data/annotations/mri_split1_p1.json',\n",
            "             'max_seq_len': 2304,\n",
            "             'num_classes': 12,\n",
            "             'num_frames': 1,\n",
            "             'trunc_thresh': 0.5},\n",
            " 'dataset_name': 'mri-rgb',\n",
            " 'devices': ['cuda:0'],\n",
            " 'init_rand_seed': 0,\n",
            " 'loader': {'batch_size': 2, 'num_workers': 4},\n",
            " 'model': {'backbone_arch': [2, 2, 5],\n",
            "           'backbone_type': 'convTransformer',\n",
            "           'embd_dim': 192,\n",
            "           'embd_kernel_size': 3,\n",
            "           'embd_with_ln': True,\n",
            "           'fpn_dim': 192,\n",
            "           'fpn_start_level': 5,\n",
            "           'fpn_type': 'identity',\n",
            "           'fpn_with_ln': True,\n",
            "           'head_dim': 192,\n",
            "           'head_kernel_size': 3,\n",
            "           'head_num_layers': 3,\n",
            "           'head_with_ln': True,\n",
            "           'input_dim': 51,\n",
            "           'max_buffer_len_factor': 2.0,\n",
            "           'max_seq_len': 2304,\n",
            "           'n_head': 4,\n",
            "           'n_mha_win_size': 19,\n",
            "           'num_classes': 12,\n",
            "           'regression_range': [[0, 10000]],\n",
            "           'scale_factor': 2,\n",
            "           'test_cfg': {'duration_thresh': 1.0,\n",
            "                        'ext_score_file': None,\n",
            "                        'iou_threshold': 0.1,\n",
            "                        'max_seg_num': 200,\n",
            "                        'min_score': 0.001,\n",
            "                        'multiclass_nms': True,\n",
            "                        'nms_method': 'soft',\n",
            "                        'nms_sigma': 0.75,\n",
            "                        'pre_nms_thresh': 0.001,\n",
            "                        'pre_nms_topk': 1000,\n",
            "                        'voting_thresh': 0.75},\n",
            "           'train_cfg': {'center_sample': 'radius',\n",
            "                         'center_sample_radius': 1.5,\n",
            "                         'clip_grad_l2norm': 1.0,\n",
            "                         'cls_prior_prob': 0.01,\n",
            "                         'dropout': 0.0,\n",
            "                         'droppath': 0.1,\n",
            "                         'head_empty_cls': [],\n",
            "                         'init_loss_norm': 100,\n",
            "                         'label_smoothing': 0.0,\n",
            "                         'loss_weight': 1.0},\n",
            "           'use_abs_pe': False,\n",
            "           'use_rel_pe': True},\n",
            " 'model_name': 'LocPointTransformer',\n",
            " 'opt': {'epochs': 100,\n",
            "         'learning_rate': 0.0001,\n",
            "         'momentum': 0.9,\n",
            "         'schedule_gamma': 0.1,\n",
            "         'schedule_steps': [],\n",
            "         'schedule_type': 'cosine',\n",
            "         'type': 'AdamW',\n",
            "         'warmup': True,\n",
            "         'warmup_epochs': 20,\n",
            "         'weight_decay': 0.05},\n",
            " 'output_folder': './ckpt/',\n",
            " 'test_cfg': {'duration_thresh': 1.0,\n",
            "              'ext_score_file': None,\n",
            "              'iou_threshold': 0.1,\n",
            "              'max_seg_num': 200,\n",
            "              'min_score': 0.001,\n",
            "              'multiclass_nms': True,\n",
            "              'nms_method': 'soft',\n",
            "              'nms_sigma': 0.75,\n",
            "              'pre_nms_thresh': 0.001,\n",
            "              'pre_nms_topk': 1000,\n",
            "              'voting_thresh': 0.75},\n",
            " 'train_cfg': {'center_sample': 'radius',\n",
            "               'center_sample_radius': 1.5,\n",
            "               'clip_grad_l2norm': 1.0,\n",
            "               'cls_prior_prob': 0.01,\n",
            "               'dropout': 0.0,\n",
            "               'droppath': 0.1,\n",
            "               'head_empty_cls': [],\n",
            "               'init_loss_norm': 100,\n",
            "               'label_smoothing': 0.0,\n",
            "               'loss_weight': 1.0},\n",
            " 'train_split': ['training'],\n",
            " 'val_split': ['validation']}\n",
            "2024-08-05 09:47:55.545767: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-05 09:47:55.577969: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-05 09:47:55.587882: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-05 09:47:55.611455: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-05 09:47:56.741719: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Using model EMA ...\n",
            "\n",
            "Start training model LocPointTransformer ...\n",
            "\n",
            "[Train]: Epoch 0 started\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch: [000][00002/00008]\tTime 5.67 (5.67)\tLoss 1.54 (1.54)\n",
            "\t\tcls_loss 0.79 (0.79)\treg_loss 0.75 (0.75)\n",
            "Epoch: [000][00004/00008]\tTime 1.87 (3.77)\tLoss 1.65 (1.60)\n",
            "\t\tcls_loss 0.86 (0.83)\treg_loss 0.80 (0.77)\n",
            "Epoch: [000][00006/00008]\tTime 1.57 (3.04)\tLoss 1.78 (1.66)\n",
            "\t\tcls_loss 0.93 (0.86)\treg_loss 0.85 (0.80)\n",
            "[Train]: Epoch 0 finished with lr=0.00000503\n",
            "\n",
            "\n",
            "[Train]: Epoch 1 started\n",
            "Epoch: [001][00002/00008]\tTime 0.77 (0.77)\tLoss 1.84 (1.84)\n",
            "\t\tcls_loss 0.97 (0.97)\treg_loss 0.88 (0.88)\n",
            "Epoch: [001][00004/00008]\tTime 0.22 (0.49)\tLoss 1.83 (1.83)\n",
            "\t\tcls_loss 0.96 (0.97)\treg_loss 0.86 (0.87)\n",
            "Epoch: [001][00006/00008]\tTime 0.25 (0.41)\tLoss 1.87 (1.85)\n",
            "\t\tcls_loss 1.00 (0.98)\treg_loss 0.87 (0.87)\n",
            "[Train]: Epoch 1 finished with lr=0.00001006\n",
            "\n",
            "\n",
            "[Train]: Epoch 2 started\n",
            "Epoch: [002][00002/00008]\tTime 1.18 (1.18)\tLoss 1.76 (1.76)\n",
            "\t\tcls_loss 0.94 (0.94)\treg_loss 0.81 (0.81)\n",
            "Epoch: [002][00004/00008]\tTime 0.29 (0.74)\tLoss 1.85 (1.80)\n",
            "\t\tcls_loss 1.01 (0.98)\treg_loss 0.85 (0.83)\n",
            "Epoch: [002][00006/00008]\tTime 0.23 (0.57)\tLoss 1.81 (1.81)\n",
            "\t\tcls_loss 0.98 (0.98)\treg_loss 0.82 (0.83)\n",
            "[Train]: Epoch 2 finished with lr=0.00001509\n",
            "\n",
            "\n",
            "[Train]: Epoch 3 started\n",
            "Epoch: [003][00002/00008]\tTime 0.72 (0.72)\tLoss 1.66 (1.66)\n",
            "\t\tcls_loss 0.93 (0.93)\treg_loss 0.74 (0.74)\n",
            "Epoch: [003][00004/00008]\tTime 0.18 (0.45)\tLoss 1.71 (1.69)\n",
            "\t\tcls_loss 0.95 (0.94)\treg_loss 0.76 (0.75)\n",
            "Epoch: [003][00006/00008]\tTime 0.19 (0.36)\tLoss 1.65 (1.68)\n",
            "\t\tcls_loss 0.92 (0.93)\treg_loss 0.73 (0.74)\n",
            "[Train]: Epoch 3 finished with lr=0.00002013\n",
            "\n",
            "\n",
            "[Train]: Epoch 4 started\n",
            "Epoch: [004][00002/00008]\tTime 0.99 (0.99)\tLoss 1.48 (1.48)\n",
            "\t\tcls_loss 0.84 (0.84)\treg_loss 0.64 (0.64)\n",
            "Epoch: [004][00004/00008]\tTime 0.24 (0.62)\tLoss 1.52 (1.50)\n",
            "\t\tcls_loss 0.86 (0.85)\treg_loss 0.66 (0.65)\n",
            "Epoch: [004][00006/00008]\tTime 0.20 (0.48)\tLoss 1.50 (1.50)\n",
            "\t\tcls_loss 0.87 (0.85)\treg_loss 0.63 (0.64)\n",
            "[Train]: Epoch 4 finished with lr=0.00002516\n",
            "\n",
            "\n",
            "[Train]: Epoch 5 started\n",
            "Epoch: [005][00002/00008]\tTime 1.09 (1.09)\tLoss 1.29 (1.29)\n",
            "\t\tcls_loss 0.79 (0.79)\treg_loss 0.50 (0.50)\n",
            "Epoch: [005][00004/00008]\tTime 0.32 (0.70)\tLoss 1.28 (1.28)\n",
            "\t\tcls_loss 0.80 (0.79)\treg_loss 0.48 (0.49)\n",
            "Epoch: [005][00006/00008]\tTime 0.18 (0.53)\tLoss 1.15 (1.24)\n",
            "\t\tcls_loss 0.74 (0.78)\treg_loss 0.41 (0.46)\n",
            "[Train]: Epoch 5 finished with lr=0.00003019\n",
            "\n",
            "\n",
            "[Train]: Epoch 6 started\n",
            "Epoch: [006][00002/00008]\tTime 0.83 (0.83)\tLoss 1.11 (1.11)\n",
            "\t\tcls_loss 0.74 (0.74)\treg_loss 0.37 (0.37)\n",
            "Epoch: [006][00004/00008]\tTime 0.25 (0.54)\tLoss 1.04 (1.08)\n",
            "\t\tcls_loss 0.70 (0.72)\treg_loss 0.34 (0.35)\n",
            "Epoch: [006][00006/00008]\tTime 0.22 (0.43)\tLoss 1.04 (1.06)\n",
            "\t\tcls_loss 0.70 (0.71)\treg_loss 0.34 (0.35)\n",
            "[Train]: Epoch 6 finished with lr=0.00003522\n",
            "\n",
            "\n",
            "[Train]: Epoch 7 started\n",
            "Epoch: [007][00002/00008]\tTime 1.05 (1.05)\tLoss 0.95 (0.95)\n",
            "\t\tcls_loss 0.64 (0.64)\treg_loss 0.31 (0.31)\n",
            "Epoch: [007][00004/00008]\tTime 0.27 (0.66)\tLoss 0.99 (0.97)\n",
            "\t\tcls_loss 0.65 (0.64)\treg_loss 0.34 (0.32)\n",
            "Epoch: [007][00006/00008]\tTime 0.24 (0.52)\tLoss 0.95 (0.96)\n",
            "\t\tcls_loss 0.63 (0.64)\treg_loss 0.32 (0.32)\n",
            "[Train]: Epoch 7 finished with lr=0.00004025\n",
            "\n",
            "\n",
            "[Train]: Epoch 8 started\n",
            "Epoch: [008][00002/00008]\tTime 0.61 (0.61)\tLoss 0.91 (0.91)\n",
            "\t\tcls_loss 0.58 (0.58)\treg_loss 0.33 (0.33)\n",
            "Epoch: [008][00004/00008]\tTime 0.23 (0.42)\tLoss 0.89 (0.90)\n",
            "\t\tcls_loss 0.57 (0.57)\treg_loss 0.33 (0.33)\n",
            "Epoch: [008][00006/00008]\tTime 0.23 (0.35)\tLoss 0.87 (0.89)\n",
            "\t\tcls_loss 0.54 (0.56)\treg_loss 0.33 (0.33)\n",
            "[Train]: Epoch 8 finished with lr=0.00004528\n",
            "\n",
            "\n",
            "[Train]: Epoch 9 started\n",
            "Epoch: [009][00002/00008]\tTime 0.77 (0.77)\tLoss 0.82 (0.82)\n",
            "\t\tcls_loss 0.49 (0.49)\treg_loss 0.33 (0.33)\n",
            "Epoch: [009][00004/00008]\tTime 0.25 (0.51)\tLoss 0.80 (0.81)\n",
            "\t\tcls_loss 0.47 (0.48)\treg_loss 0.33 (0.33)\n",
            "Epoch: [009][00006/00008]\tTime 0.18 (0.40)\tLoss 0.76 (0.79)\n",
            "\t\tcls_loss 0.45 (0.47)\treg_loss 0.31 (0.32)\n",
            "[Train]: Epoch 9 finished with lr=0.00005031\n",
            "\n",
            "\n",
            "[Train]: Epoch 10 started\n",
            "Epoch: [010][00002/00008]\tTime 0.86 (0.86)\tLoss 0.70 (0.70)\n",
            "\t\tcls_loss 0.40 (0.40)\treg_loss 0.30 (0.30)\n",
            "Epoch: [010][00004/00008]\tTime 0.19 (0.52)\tLoss 0.70 (0.70)\n",
            "\t\tcls_loss 0.37 (0.39)\treg_loss 0.32 (0.31)\n",
            "Epoch: [010][00006/00008]\tTime 0.18 (0.41)\tLoss 0.65 (0.68)\n",
            "\t\tcls_loss 0.34 (0.37)\treg_loss 0.31 (0.31)\n",
            "[Train]: Epoch 10 finished with lr=0.00005535\n",
            "\n",
            "\n",
            "[Train]: Epoch 11 started\n",
            "Epoch: [011][00002/00008]\tTime 0.76 (0.76)\tLoss 0.60 (0.60)\n",
            "\t\tcls_loss 0.30 (0.30)\treg_loss 0.29 (0.29)\n",
            "Epoch: [011][00004/00008]\tTime 0.18 (0.47)\tLoss 0.58 (0.59)\n",
            "\t\tcls_loss 0.28 (0.29)\treg_loss 0.30 (0.30)\n",
            "Epoch: [011][00006/00008]\tTime 0.24 (0.39)\tLoss 0.57 (0.58)\n",
            "\t\tcls_loss 0.26 (0.28)\treg_loss 0.31 (0.30)\n",
            "[Train]: Epoch 11 finished with lr=0.00006038\n",
            "\n",
            "\n",
            "[Train]: Epoch 12 started\n",
            "Epoch: [012][00002/00008]\tTime 0.86 (0.86)\tLoss 0.50 (0.50)\n",
            "\t\tcls_loss 0.22 (0.22)\treg_loss 0.28 (0.28)\n",
            "Epoch: [012][00004/00008]\tTime 0.24 (0.55)\tLoss 0.46 (0.48)\n",
            "\t\tcls_loss 0.21 (0.21)\treg_loss 0.25 (0.27)\n",
            "Epoch: [012][00006/00008]\tTime 0.23 (0.44)\tLoss 0.44 (0.47)\n",
            "\t\tcls_loss 0.18 (0.20)\treg_loss 0.26 (0.26)\n",
            "[Train]: Epoch 12 finished with lr=0.00006541\n",
            "\n",
            "\n",
            "[Train]: Epoch 13 started\n",
            "Epoch: [013][00002/00008]\tTime 0.72 (0.72)\tLoss 0.42 (0.42)\n",
            "\t\tcls_loss 0.17 (0.17)\treg_loss 0.25 (0.25)\n",
            "Epoch: [013][00004/00008]\tTime 0.20 (0.46)\tLoss 0.38 (0.40)\n",
            "\t\tcls_loss 0.16 (0.17)\treg_loss 0.23 (0.24)\n",
            "Epoch: [013][00006/00008]\tTime 0.18 (0.37)\tLoss 0.37 (0.39)\n",
            "\t\tcls_loss 0.15 (0.16)\treg_loss 0.22 (0.23)\n",
            "[Train]: Epoch 13 finished with lr=0.00007044\n",
            "\n",
            "\n",
            "[Train]: Epoch 14 started\n",
            "Epoch: [014][00002/00008]\tTime 0.78 (0.78)\tLoss 0.33 (0.33)\n",
            "\t\tcls_loss 0.13 (0.13)\treg_loss 0.20 (0.20)\n",
            "Epoch: [014][00004/00008]\tTime 0.26 (0.52)\tLoss 0.30 (0.32)\n",
            "\t\tcls_loss 0.12 (0.12)\treg_loss 0.18 (0.19)\n",
            "Epoch: [014][00006/00008]\tTime 0.19 (0.41)\tLoss 0.30 (0.31)\n",
            "\t\tcls_loss 0.11 (0.12)\treg_loss 0.19 (0.19)\n",
            "[Train]: Epoch 14 finished with lr=0.00007547\n",
            "\n",
            "\n",
            "[Train]: Epoch 15 started\n",
            "Epoch: [015][00002/00008]\tTime 0.60 (0.60)\tLoss 0.29 (0.29)\n",
            "\t\tcls_loss 0.10 (0.10)\treg_loss 0.19 (0.19)\n",
            "Epoch: [015][00004/00008]\tTime 0.22 (0.41)\tLoss 0.27 (0.28)\n",
            "\t\tcls_loss 0.10 (0.10)\treg_loss 0.17 (0.18)\n",
            "Epoch: [015][00006/00008]\tTime 0.18 (0.33)\tLoss 0.25 (0.27)\n",
            "\t\tcls_loss 0.09 (0.10)\treg_loss 0.17 (0.17)\n",
            "[Train]: Epoch 15 finished with lr=0.00008050\n",
            "\n",
            "\n",
            "[Train]: Epoch 16 started\n",
            "Epoch: [016][00002/00008]\tTime 1.10 (1.10)\tLoss 0.25 (0.25)\n",
            "\t\tcls_loss 0.08 (0.08)\treg_loss 0.17 (0.17)\n",
            "Epoch: [016][00004/00008]\tTime 0.48 (0.79)\tLoss 0.22 (0.23)\n",
            "\t\tcls_loss 0.08 (0.08)\treg_loss 0.14 (0.16)\n",
            "Epoch: [016][00006/00008]\tTime 0.19 (0.59)\tLoss 0.25 (0.24)\n",
            "\t\tcls_loss 0.09 (0.08)\treg_loss 0.16 (0.16)\n",
            "[Train]: Epoch 16 finished with lr=0.00008553\n",
            "\n",
            "\n",
            "[Train]: Epoch 17 started\n",
            "Epoch: [017][00002/00008]\tTime 0.93 (0.93)\tLoss 0.24 (0.24)\n",
            "\t\tcls_loss 0.08 (0.08)\treg_loss 0.16 (0.16)\n",
            "Epoch: [017][00004/00008]\tTime 0.41 (0.67)\tLoss 0.20 (0.22)\n",
            "\t\tcls_loss 0.07 (0.08)\treg_loss 0.12 (0.14)\n",
            "Epoch: [017][00006/00008]\tTime 0.22 (0.52)\tLoss 0.25 (0.23)\n",
            "\t\tcls_loss 0.08 (0.08)\treg_loss 0.16 (0.15)\n",
            "[Train]: Epoch 17 finished with lr=0.00009057\n",
            "\n",
            "\n",
            "[Train]: Epoch 18 started\n",
            "Epoch: [018][00002/00008]\tTime 0.83 (0.83)\tLoss 0.22 (0.22)\n",
            "\t\tcls_loss 0.08 (0.08)\treg_loss 0.14 (0.14)\n",
            "Epoch: [018][00004/00008]\tTime 0.30 (0.56)\tLoss 0.21 (0.21)\n",
            "\t\tcls_loss 0.07 (0.07)\treg_loss 0.15 (0.14)\n",
            "Epoch: [018][00006/00008]\tTime 0.18 (0.43)\tLoss 0.25 (0.23)\n",
            "\t\tcls_loss 0.08 (0.07)\treg_loss 0.17 (0.15)\n",
            "[Train]: Epoch 18 finished with lr=0.00009560\n",
            "\n",
            "\n",
            "[Train]: Epoch 19 started\n",
            "Epoch: [019][00002/00008]\tTime 0.57 (0.57)\tLoss 0.19 (0.19)\n",
            "\t\tcls_loss 0.07 (0.07)\treg_loss 0.12 (0.12)\n",
            "Epoch: [019][00004/00008]\tTime 0.22 (0.40)\tLoss 0.20 (0.19)\n",
            "\t\tcls_loss 0.07 (0.07)\treg_loss 0.13 (0.13)\n",
            "Epoch: [019][00006/00008]\tTime 0.18 (0.32)\tLoss 0.20 (0.19)\n",
            "\t\tcls_loss 0.07 (0.07)\treg_loss 0.13 (0.13)\n",
            "[Train]: Epoch 19 finished with lr=0.00010000\n",
            "\n",
            "\n",
            "[Train]: Epoch 20 started\n",
            "Epoch: [020][00002/00008]\tTime 0.60 (0.60)\tLoss 0.19 (0.19)\n",
            "\t\tcls_loss 0.06 (0.06)\treg_loss 0.13 (0.13)\n",
            "Epoch: [020][00004/00008]\tTime 0.27 (0.44)\tLoss 0.19 (0.19)\n",
            "\t\tcls_loss 0.07 (0.07)\treg_loss 0.12 (0.13)\n",
            "Epoch: [020][00006/00008]\tTime 0.18 (0.35)\tLoss 0.18 (0.19)\n",
            "\t\tcls_loss 0.05 (0.06)\treg_loss 0.12 (0.13)\n",
            "[Train]: Epoch 20 finished with lr=0.00009998\n",
            "\n",
            "\n",
            "[Train]: Epoch 21 started\n",
            "Epoch: [021][00002/00008]\tTime 0.61 (0.61)\tLoss 0.18 (0.18)\n",
            "\t\tcls_loss 0.05 (0.05)\treg_loss 0.13 (0.13)\n",
            "Epoch: [021][00004/00008]\tTime 0.19 (0.40)\tLoss 0.17 (0.17)\n",
            "\t\tcls_loss 0.06 (0.06)\treg_loss 0.11 (0.12)\n",
            "Epoch: [021][00006/00008]\tTime 0.18 (0.33)\tLoss 0.17 (0.17)\n",
            "\t\tcls_loss 0.05 (0.06)\treg_loss 0.12 (0.12)\n",
            "[Train]: Epoch 21 finished with lr=0.00009990\n",
            "\n",
            "\n",
            "[Train]: Epoch 22 started\n",
            "Epoch: [022][00002/00008]\tTime 0.55 (0.55)\tLoss 0.18 (0.18)\n",
            "\t\tcls_loss 0.05 (0.05)\treg_loss 0.12 (0.12)\n",
            "Epoch: [022][00004/00008]\tTime 0.33 (0.44)\tLoss 0.16 (0.17)\n",
            "\t\tcls_loss 0.05 (0.05)\treg_loss 0.11 (0.12)\n",
            "Epoch: [022][00006/00008]\tTime 0.21 (0.36)\tLoss 0.15 (0.16)\n",
            "\t\tcls_loss 0.05 (0.05)\treg_loss 0.10 (0.11)\n",
            "[Train]: Epoch 22 finished with lr=0.00009978\n",
            "\n",
            "\n",
            "[Train]: Epoch 23 started\n",
            "Epoch: [023][00002/00008]\tTime 0.74 (0.74)\tLoss 0.16 (0.16)\n",
            "\t\tcls_loss 0.05 (0.05)\treg_loss 0.11 (0.11)\n",
            "Epoch: [023][00004/00008]\tTime 0.30 (0.52)\tLoss 0.20 (0.18)\n",
            "\t\tcls_loss 0.06 (0.06)\treg_loss 0.14 (0.13)\n",
            "Epoch: [023][00006/00008]\tTime 0.32 (0.46)\tLoss 0.17 (0.18)\n",
            "\t\tcls_loss 0.05 (0.05)\treg_loss 0.12 (0.12)\n",
            "[Train]: Epoch 23 finished with lr=0.00009961\n",
            "\n",
            "\n",
            "[Train]: Epoch 24 started\n",
            "Epoch: [024][00002/00008]\tTime 0.67 (0.67)\tLoss 0.19 (0.19)\n",
            "\t\tcls_loss 0.06 (0.06)\treg_loss 0.13 (0.13)\n",
            "Epoch: [024][00004/00008]\tTime 0.18 (0.43)\tLoss 0.15 (0.17)\n",
            "\t\tcls_loss 0.05 (0.06)\treg_loss 0.10 (0.11)\n",
            "Epoch: [024][00006/00008]\tTime 0.19 (0.35)\tLoss 0.18 (0.17)\n",
            "\t\tcls_loss 0.06 (0.06)\treg_loss 0.12 (0.12)\n",
            "[Train]: Epoch 24 finished with lr=0.00009938\n",
            "\n",
            "\n",
            "[Train]: Epoch 25 started\n",
            "Epoch: [025][00002/00008]\tTime 0.43 (0.43)\tLoss 0.17 (0.17)\n",
            "\t\tcls_loss 0.06 (0.06)\treg_loss 0.12 (0.12)\n",
            "Epoch: [025][00004/00008]\tTime 0.21 (0.32)\tLoss 0.13 (0.15)\n",
            "\t\tcls_loss 0.05 (0.05)\treg_loss 0.08 (0.10)\n",
            "Epoch: [025][00006/00008]\tTime 0.19 (0.28)\tLoss 0.14 (0.15)\n",
            "\t\tcls_loss 0.04 (0.05)\treg_loss 0.10 (0.10)\n",
            "[Train]: Epoch 25 finished with lr=0.00009911\n",
            "\n",
            "\n",
            "[Train]: Epoch 26 started\n",
            "Epoch: [026][00002/00008]\tTime 0.78 (0.78)\tLoss 0.16 (0.16)\n",
            "\t\tcls_loss 0.05 (0.05)\treg_loss 0.11 (0.11)\n",
            "Epoch: [026][00004/00008]\tTime 0.18 (0.48)\tLoss 0.15 (0.15)\n",
            "\t\tcls_loss 0.05 (0.05)\treg_loss 0.10 (0.10)\n",
            "Epoch: [026][00006/00008]\tTime 0.17 (0.38)\tLoss 0.14 (0.15)\n",
            "\t\tcls_loss 0.04 (0.05)\treg_loss 0.09 (0.10)\n",
            "[Train]: Epoch 26 finished with lr=0.00009880\n",
            "\n",
            "\n",
            "[Train]: Epoch 27 started\n",
            "Epoch: [027][00002/00008]\tTime 0.59 (0.59)\tLoss 0.17 (0.17)\n",
            "\t\tcls_loss 0.06 (0.06)\treg_loss 0.12 (0.12)\n",
            "Epoch: [027][00004/00008]\tTime 0.23 (0.41)\tLoss 0.15 (0.16)\n",
            "\t\tcls_loss 0.05 (0.05)\treg_loss 0.10 (0.11)\n",
            "Epoch: [027][00006/00008]\tTime 0.19 (0.34)\tLoss 0.16 (0.16)\n",
            "\t\tcls_loss 0.04 (0.05)\treg_loss 0.12 (0.11)\n",
            "[Train]: Epoch 27 finished with lr=0.00009843\n",
            "\n",
            "\n",
            "[Train]: Epoch 28 started\n",
            "Epoch: [028][00002/00008]\tTime 0.58 (0.58)\tLoss 0.14 (0.14)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.09 (0.09)\n",
            "Epoch: [028][00004/00008]\tTime 0.18 (0.38)\tLoss 0.12 (0.13)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.08 (0.09)\n",
            "Epoch: [028][00006/00008]\tTime 0.21 (0.33)\tLoss 0.14 (0.13)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.10 (0.09)\n",
            "[Train]: Epoch 28 finished with lr=0.00009801\n",
            "\n",
            "\n",
            "[Train]: Epoch 29 started\n",
            "Epoch: [029][00002/00008]\tTime 0.64 (0.64)\tLoss 0.14 (0.14)\n",
            "\t\tcls_loss 0.05 (0.05)\treg_loss 0.09 (0.09)\n",
            "Epoch: [029][00004/00008]\tTime 0.28 (0.46)\tLoss 0.15 (0.14)\n",
            "\t\tcls_loss 0.05 (0.05)\treg_loss 0.10 (0.10)\n",
            "Epoch: [029][00006/00008]\tTime 0.23 (0.38)\tLoss 0.14 (0.14)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.10 (0.10)\n",
            "[Train]: Epoch 29 finished with lr=0.00009755\n",
            "\n",
            "\n",
            "[Train]: Epoch 30 started\n",
            "Epoch: [030][00002/00008]\tTime 0.80 (0.80)\tLoss 0.12 (0.12)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.08 (0.08)\n",
            "Epoch: [030][00004/00008]\tTime 0.23 (0.52)\tLoss 0.14 (0.13)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.10 (0.09)\n",
            "Epoch: [030][00006/00008]\tTime 0.17 (0.40)\tLoss 0.15 (0.13)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.11 (0.09)\n",
            "[Train]: Epoch 30 finished with lr=0.00009704\n",
            "\n",
            "\n",
            "[Train]: Epoch 31 started\n",
            "Epoch: [031][00002/00008]\tTime 0.40 (0.40)\tLoss 0.15 (0.15)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.11 (0.11)\n",
            "Epoch: [031][00004/00008]\tTime 0.21 (0.30)\tLoss 0.11 (0.13)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.07 (0.09)\n",
            "Epoch: [031][00006/00008]\tTime 0.18 (0.26)\tLoss 0.14 (0.13)\n",
            "\t\tcls_loss 0.05 (0.04)\treg_loss 0.09 (0.09)\n",
            "[Train]: Epoch 31 finished with lr=0.00009649\n",
            "\n",
            "\n",
            "[Train]: Epoch 32 started\n",
            "Epoch: [032][00002/00008]\tTime 0.57 (0.57)\tLoss 0.13 (0.13)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.09 (0.09)\n",
            "Epoch: [032][00004/00008]\tTime 0.18 (0.38)\tLoss 0.13 (0.13)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.09 (0.09)\n",
            "Epoch: [032][00006/00008]\tTime 0.18 (0.31)\tLoss 0.16 (0.14)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.12 (0.10)\n",
            "[Train]: Epoch 32 finished with lr=0.00009589\n",
            "\n",
            "\n",
            "[Train]: Epoch 33 started\n",
            "Epoch: [033][00002/00008]\tTime 0.38 (0.38)\tLoss 0.13 (0.13)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.09 (0.09)\n",
            "Epoch: [033][00004/00008]\tTime 0.20 (0.29)\tLoss 0.11 (0.12)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.07 (0.08)\n",
            "Epoch: [033][00006/00008]\tTime 0.19 (0.26)\tLoss 0.15 (0.13)\n",
            "\t\tcls_loss 0.06 (0.05)\treg_loss 0.09 (0.08)\n",
            "[Train]: Epoch 33 finished with lr=0.00009524\n",
            "\n",
            "\n",
            "[Train]: Epoch 34 started\n",
            "Epoch: [034][00002/00008]\tTime 0.62 (0.62)\tLoss 0.13 (0.13)\n",
            "\t\tcls_loss 0.05 (0.05)\treg_loss 0.08 (0.08)\n",
            "Epoch: [034][00004/00008]\tTime 0.26 (0.44)\tLoss 0.14 (0.14)\n",
            "\t\tcls_loss 0.05 (0.05)\treg_loss 0.10 (0.09)\n",
            "Epoch: [034][00006/00008]\tTime 0.23 (0.37)\tLoss 0.15 (0.14)\n",
            "\t\tcls_loss 0.04 (0.05)\treg_loss 0.11 (0.10)\n",
            "[Train]: Epoch 34 finished with lr=0.00009455\n",
            "\n",
            "\n",
            "[Train]: Epoch 35 started\n",
            "Epoch: [035][00002/00008]\tTime 0.61 (0.61)\tLoss 0.16 (0.16)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.11 (0.11)\n",
            "Epoch: [035][00004/00008]\tTime 0.23 (0.42)\tLoss 0.10 (0.13)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.07 (0.09)\n",
            "Epoch: [035][00006/00008]\tTime 0.22 (0.35)\tLoss 0.10 (0.12)\n",
            "\t\tcls_loss 0.03 (0.04)\treg_loss 0.07 (0.08)\n",
            "[Train]: Epoch 35 finished with lr=0.00009382\n",
            "\n",
            "\n",
            "[Train]: Epoch 36 started\n",
            "Epoch: [036][00002/00008]\tTime 0.59 (0.59)\tLoss 0.12 (0.12)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.09 (0.09)\n",
            "Epoch: [036][00004/00008]\tTime 0.25 (0.42)\tLoss 0.14 (0.13)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.10 (0.09)\n",
            "Epoch: [036][00006/00008]\tTime 0.23 (0.36)\tLoss 0.11 (0.12)\n",
            "\t\tcls_loss 0.03 (0.04)\treg_loss 0.07 (0.09)\n",
            "[Train]: Epoch 36 finished with lr=0.00009304\n",
            "\n",
            "\n",
            "[Train]: Epoch 37 started\n",
            "Epoch: [037][00002/00008]\tTime 0.61 (0.61)\tLoss 0.11 (0.11)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.08 (0.08)\n",
            "Epoch: [037][00004/00008]\tTime 0.21 (0.41)\tLoss 0.12 (0.11)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.08 (0.08)\n",
            "Epoch: [037][00006/00008]\tTime 0.19 (0.34)\tLoss 0.10 (0.11)\n",
            "\t\tcls_loss 0.03 (0.04)\treg_loss 0.07 (0.08)\n",
            "[Train]: Epoch 37 finished with lr=0.00009222\n",
            "\n",
            "\n",
            "[Train]: Epoch 38 started\n",
            "Epoch: [038][00002/00008]\tTime 0.60 (0.60)\tLoss 0.10 (0.10)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.07 (0.07)\n",
            "Epoch: [038][00004/00008]\tTime 0.23 (0.42)\tLoss 0.11 (0.10)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.07 (0.07)\n",
            "Epoch: [038][00006/00008]\tTime 0.23 (0.35)\tLoss 0.11 (0.11)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.08 (0.07)\n",
            "[Train]: Epoch 38 finished with lr=0.00009135\n",
            "\n",
            "\n",
            "[Train]: Epoch 39 started\n",
            "Epoch: [039][00002/00008]\tTime 0.69 (0.69)\tLoss 0.09 (0.09)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.07 (0.07)\n",
            "Epoch: [039][00004/00008]\tTime 0.18 (0.43)\tLoss 0.12 (0.10)\n",
            "\t\tcls_loss 0.05 (0.04)\treg_loss 0.07 (0.07)\n",
            "Epoch: [039][00006/00008]\tTime 0.18 (0.35)\tLoss 0.12 (0.11)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.08 (0.07)\n",
            "[Train]: Epoch 39 finished with lr=0.00009045\n",
            "\n",
            "\n",
            "[Train]: Epoch 40 started\n",
            "Epoch: [040][00002/00008]\tTime 0.44 (0.44)\tLoss 0.12 (0.12)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.08 (0.08)\n",
            "Epoch: [040][00004/00008]\tTime 0.19 (0.31)\tLoss 0.11 (0.12)\n",
            "\t\tcls_loss 0.03 (0.04)\treg_loss 0.08 (0.08)\n",
            "Epoch: [040][00006/00008]\tTime 0.18 (0.27)\tLoss 0.13 (0.12)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.08 (0.08)\n",
            "[Train]: Epoch 40 finished with lr=0.00008951\n",
            "\n",
            "\n",
            "[Train]: Epoch 41 started\n",
            "Epoch: [041][00002/00008]\tTime 0.79 (0.79)\tLoss 0.11 (0.11)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.07 (0.07)\n",
            "Epoch: [041][00004/00008]\tTime 0.21 (0.50)\tLoss 0.13 (0.12)\n",
            "\t\tcls_loss 0.05 (0.04)\treg_loss 0.09 (0.08)\n",
            "Epoch: [041][00006/00008]\tTime 0.22 (0.41)\tLoss 0.08 (0.11)\n",
            "\t\tcls_loss 0.02 (0.04)\treg_loss 0.05 (0.07)\n",
            "[Train]: Epoch 41 finished with lr=0.00008853\n",
            "\n",
            "\n",
            "[Train]: Epoch 42 started\n",
            "Epoch: [042][00002/00008]\tTime 0.74 (0.74)\tLoss 0.09 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.06)\n",
            "Epoch: [042][00004/00008]\tTime 0.24 (0.49)\tLoss 0.09 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.06)\n",
            "Epoch: [042][00006/00008]\tTime 0.23 (0.40)\tLoss 0.11 (0.10)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.07 (0.06)\n",
            "[Train]: Epoch 42 finished with lr=0.00008751\n",
            "\n",
            "\n",
            "[Train]: Epoch 43 started\n",
            "Epoch: [043][00002/00008]\tTime 0.73 (0.73)\tLoss 0.08 (0.08)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.06 (0.06)\n",
            "Epoch: [043][00004/00008]\tTime 0.19 (0.46)\tLoss 0.12 (0.10)\n",
            "\t\tcls_loss 0.04 (0.03)\treg_loss 0.08 (0.07)\n",
            "Epoch: [043][00006/00008]\tTime 0.17 (0.36)\tLoss 0.10 (0.10)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.07 (0.07)\n",
            "[Train]: Epoch 43 finished with lr=0.00008645\n",
            "\n",
            "\n",
            "[Train]: Epoch 44 started\n",
            "Epoch: [044][00002/00008]\tTime 0.56 (0.56)\tLoss 0.08 (0.08)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.06 (0.06)\n",
            "Epoch: [044][00004/00008]\tTime 0.19 (0.37)\tLoss 0.09 (0.08)\n",
            "\t\tcls_loss 0.03 (0.02)\treg_loss 0.06 (0.06)\n",
            "Epoch: [044][00006/00008]\tTime 0.18 (0.31)\tLoss 0.09 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.07 (0.06)\n",
            "[Train]: Epoch 44 finished with lr=0.00008536\n",
            "\n",
            "\n",
            "[Train]: Epoch 45 started\n",
            "Epoch: [045][00002/00008]\tTime 0.62 (0.62)\tLoss 0.09 (0.09)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.05 (0.05)\n",
            "Epoch: [045][00004/00008]\tTime 0.19 (0.41)\tLoss 0.09 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.06)\n",
            "Epoch: [045][00006/00008]\tTime 0.18 (0.33)\tLoss 0.10 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.07 (0.06)\n",
            "[Train]: Epoch 45 finished with lr=0.00008423\n",
            "\n",
            "\n",
            "[Train]: Epoch 46 started\n",
            "Epoch: [046][00002/00008]\tTime 0.64 (0.64)\tLoss 0.10 (0.10)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.06 (0.06)\n",
            "Epoch: [046][00004/00008]\tTime 0.18 (0.41)\tLoss 0.13 (0.11)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.09 (0.07)\n",
            "Epoch: [046][00006/00008]\tTime 0.19 (0.33)\tLoss 0.11 (0.11)\n",
            "\t\tcls_loss 0.03 (0.04)\treg_loss 0.08 (0.08)\n",
            "[Train]: Epoch 46 finished with lr=0.00008307\n",
            "\n",
            "\n",
            "[Train]: Epoch 47 started\n",
            "Epoch: [047][00002/00008]\tTime 0.49 (0.49)\tLoss 0.11 (0.11)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.08 (0.08)\n",
            "Epoch: [047][00004/00008]\tTime 0.20 (0.35)\tLoss 0.13 (0.12)\n",
            "\t\tcls_loss 0.04 (0.03)\treg_loss 0.09 (0.08)\n",
            "Epoch: [047][00006/00008]\tTime 0.19 (0.30)\tLoss 0.11 (0.12)\n",
            "\t\tcls_loss 0.04 (0.03)\treg_loss 0.08 (0.08)\n",
            "[Train]: Epoch 47 finished with lr=0.00008187\n",
            "\n",
            "\n",
            "[Train]: Epoch 48 started\n",
            "Epoch: [048][00002/00008]\tTime 0.67 (0.67)\tLoss 0.10 (0.10)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.07 (0.07)\n",
            "Epoch: [048][00004/00008]\tTime 0.24 (0.45)\tLoss 0.15 (0.12)\n",
            "\t\tcls_loss 0.04 (0.03)\treg_loss 0.11 (0.09)\n",
            "Epoch: [048][00006/00008]\tTime 0.21 (0.37)\tLoss 0.09 (0.11)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.07 (0.08)\n",
            "[Train]: Epoch 48 finished with lr=0.00008065\n",
            "\n",
            "\n",
            "[Train]: Epoch 49 started\n",
            "Epoch: [049][00002/00008]\tTime 0.99 (0.99)\tLoss 0.09 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.06)\n",
            "Epoch: [049][00004/00008]\tTime 0.28 (0.64)\tLoss 0.09 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.06)\n",
            "Epoch: [049][00006/00008]\tTime 0.21 (0.50)\tLoss 0.09 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.06)\n",
            "[Train]: Epoch 49 finished with lr=0.00007939\n",
            "\n",
            "\n",
            "[Train]: Epoch 50 started\n",
            "Epoch: [050][00002/00008]\tTime 0.47 (0.47)\tLoss 0.08 (0.08)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.06)\n",
            "Epoch: [050][00004/00008]\tTime 0.22 (0.35)\tLoss 0.11 (0.10)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.08 (0.07)\n",
            "Epoch: [050][00006/00008]\tTime 0.18 (0.29)\tLoss 0.09 (0.09)\n",
            "\t\tcls_loss 0.02 (0.03)\treg_loss 0.06 (0.07)\n",
            "[Train]: Epoch 50 finished with lr=0.00007811\n",
            "\n",
            "\n",
            "[Train]: Epoch 51 started\n",
            "Epoch: [051][00002/00008]\tTime 0.56 (0.56)\tLoss 0.10 (0.10)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.07 (0.07)\n",
            "Epoch: [051][00004/00008]\tTime 0.18 (0.37)\tLoss 0.10 (0.10)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.07 (0.07)\n",
            "Epoch: [051][00006/00008]\tTime 0.18 (0.31)\tLoss 0.08 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.07)\n",
            "[Train]: Epoch 51 finished with lr=0.00007679\n",
            "\n",
            "\n",
            "[Train]: Epoch 52 started\n",
            "Epoch: [052][00002/00008]\tTime 0.60 (0.60)\tLoss 0.08 (0.08)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.06 (0.06)\n",
            "Epoch: [052][00004/00008]\tTime 0.18 (0.39)\tLoss 0.10 (0.09)\n",
            "\t\tcls_loss 0.03 (0.02)\treg_loss 0.07 (0.06)\n",
            "Epoch: [052][00006/00008]\tTime 0.19 (0.33)\tLoss 0.11 (0.10)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.08 (0.07)\n",
            "[Train]: Epoch 52 finished with lr=0.00007545\n",
            "\n",
            "\n",
            "[Train]: Epoch 53 started\n",
            "Epoch: [053][00002/00008]\tTime 0.58 (0.58)\tLoss 0.09 (0.09)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.06 (0.06)\n",
            "Epoch: [053][00004/00008]\tTime 0.19 (0.38)\tLoss 0.09 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.06)\n",
            "Epoch: [053][00006/00008]\tTime 0.26 (0.34)\tLoss 0.08 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.06)\n",
            "[Train]: Epoch 53 finished with lr=0.00007409\n",
            "\n",
            "\n",
            "[Train]: Epoch 54 started\n",
            "Epoch: [054][00002/00008]\tTime 0.69 (0.69)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "Epoch: [054][00004/00008]\tTime 0.21 (0.45)\tLoss 0.09 (0.08)\n",
            "\t\tcls_loss 0.03 (0.02)\treg_loss 0.06 (0.06)\n",
            "Epoch: [054][00006/00008]\tTime 0.21 (0.37)\tLoss 0.08 (0.08)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.06)\n",
            "[Train]: Epoch 54 finished with lr=0.00007270\n",
            "\n",
            "\n",
            "[Train]: Epoch 55 started\n",
            "Epoch: [055][00002/00008]\tTime 0.73 (0.73)\tLoss 0.10 (0.10)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.07 (0.07)\n",
            "Epoch: [055][00004/00008]\tTime 0.23 (0.48)\tLoss 0.07 (0.09)\n",
            "\t\tcls_loss 0.02 (0.03)\treg_loss 0.05 (0.06)\n",
            "Epoch: [055][00006/00008]\tTime 0.26 (0.41)\tLoss 0.08 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.06)\n",
            "[Train]: Epoch 55 finished with lr=0.00007129\n",
            "\n",
            "\n",
            "[Train]: Epoch 56 started\n",
            "Epoch: [056][00002/00008]\tTime 0.71 (0.71)\tLoss 0.09 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.06)\n",
            "Epoch: [056][00004/00008]\tTime 0.18 (0.44)\tLoss 0.08 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.06)\n",
            "Epoch: [056][00006/00008]\tTime 0.19 (0.36)\tLoss 0.08 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.05 (0.06)\n",
            "[Train]: Epoch 56 finished with lr=0.00006986\n",
            "\n",
            "\n",
            "[Train]: Epoch 57 started\n",
            "Epoch: [057][00002/00008]\tTime 0.62 (0.62)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.04 (0.04)\n",
            "Epoch: [057][00004/00008]\tTime 0.19 (0.40)\tLoss 0.11 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.07 (0.06)\n",
            "Epoch: [057][00006/00008]\tTime 0.18 (0.33)\tLoss 0.09 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.06)\n",
            "[Train]: Epoch 57 finished with lr=0.00006841\n",
            "\n",
            "\n",
            "[Train]: Epoch 58 started\n",
            "Epoch: [058][00002/00008]\tTime 0.42 (0.42)\tLoss 0.08 (0.08)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.06 (0.06)\n",
            "Epoch: [058][00004/00008]\tTime 0.18 (0.30)\tLoss 0.08 (0.08)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.06 (0.06)\n",
            "Epoch: [058][00006/00008]\tTime 0.18 (0.26)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "[Train]: Epoch 58 finished with lr=0.00006694\n",
            "\n",
            "\n",
            "[Train]: Epoch 59 started\n",
            "Epoch: [059][00002/00008]\tTime 0.55 (0.55)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "Epoch: [059][00004/00008]\tTime 0.19 (0.37)\tLoss 0.11 (0.09)\n",
            "\t\tcls_loss 0.04 (0.03)\treg_loss 0.07 (0.06)\n",
            "Epoch: [059][00006/00008]\tTime 0.19 (0.31)\tLoss 0.09 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.07 (0.06)\n",
            "[Train]: Epoch 59 finished with lr=0.00006545\n",
            "\n",
            "\n",
            "[Train]: Epoch 60 started\n",
            "Epoch: [060][00002/00008]\tTime 0.54 (0.54)\tLoss 0.09 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.05 (0.05)\n",
            "Epoch: [060][00004/00008]\tTime 0.24 (0.39)\tLoss 0.08 (0.09)\n",
            "\t\tcls_loss 0.02 (0.03)\treg_loss 0.06 (0.06)\n",
            "Epoch: [060][00006/00008]\tTime 0.22 (0.33)\tLoss 0.07 (0.08)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.06)\n",
            "[Train]: Epoch 60 finished with lr=0.00006395\n",
            "\n",
            "\n",
            "[Train]: Epoch 61 started\n",
            "Epoch: [061][00002/00008]\tTime 0.76 (0.76)\tLoss 0.08 (0.08)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "Epoch: [061][00004/00008]\tTime 0.23 (0.50)\tLoss 0.08 (0.08)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.05 (0.05)\n",
            "Epoch: [061][00006/00008]\tTime 0.21 (0.40)\tLoss 0.08 (0.08)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.05 (0.05)\n",
            "[Train]: Epoch 61 finished with lr=0.00006244\n",
            "\n",
            "\n",
            "[Train]: Epoch 62 started\n",
            "Epoch: [062][00002/00008]\tTime 0.63 (0.63)\tLoss 0.10 (0.10)\n",
            "\t\tcls_loss 0.04 (0.04)\treg_loss 0.06 (0.06)\n",
            "Epoch: [062][00004/00008]\tTime 0.25 (0.44)\tLoss 0.07 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.05 (0.05)\n",
            "Epoch: [062][00006/00008]\tTime 0.23 (0.37)\tLoss 0.08 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.06)\n",
            "[Train]: Epoch 62 finished with lr=0.00006091\n",
            "\n",
            "\n",
            "[Train]: Epoch 63 started\n",
            "Epoch: [063][00002/00008]\tTime 0.63 (0.63)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.04 (0.04)\n",
            "Epoch: [063][00004/00008]\tTime 0.23 (0.43)\tLoss 0.09 (0.08)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.05)\n",
            "Epoch: [063][00006/00008]\tTime 0.19 (0.35)\tLoss 0.07 (0.08)\n",
            "\t\tcls_loss 0.01 (0.02)\treg_loss 0.05 (0.05)\n",
            "[Train]: Epoch 63 finished with lr=0.00005937\n",
            "\n",
            "\n",
            "[Train]: Epoch 64 started\n",
            "Epoch: [064][00002/00008]\tTime 0.78 (0.78)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "Epoch: [064][00004/00008]\tTime 0.22 (0.50)\tLoss 0.10 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.07 (0.06)\n",
            "Epoch: [064][00006/00008]\tTime 0.18 (0.39)\tLoss 0.06 (0.08)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.05)\n",
            "[Train]: Epoch 64 finished with lr=0.00005783\n",
            "\n",
            "\n",
            "[Train]: Epoch 65 started\n",
            "Epoch: [065][00002/00008]\tTime 0.65 (0.65)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "Epoch: [065][00004/00008]\tTime 0.18 (0.41)\tLoss 0.09 (0.08)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.05 (0.05)\n",
            "Epoch: [065][00006/00008]\tTime 0.18 (0.34)\tLoss 0.07 (0.08)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.04 (0.05)\n",
            "[Train]: Epoch 65 finished with lr=0.00005627\n",
            "\n",
            "\n",
            "[Train]: Epoch 66 started\n",
            "Epoch: [066][00002/00008]\tTime 0.37 (0.37)\tLoss 0.09 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.06)\n",
            "Epoch: [066][00004/00008]\tTime 0.22 (0.29)\tLoss 0.06 (0.08)\n",
            "\t\tcls_loss 0.01 (0.02)\treg_loss 0.05 (0.06)\n",
            "Epoch: [066][00006/00008]\tTime 0.18 (0.26)\tLoss 0.08 (0.08)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.07 (0.06)\n",
            "[Train]: Epoch 66 finished with lr=0.00005471\n",
            "\n",
            "\n",
            "[Train]: Epoch 67 started\n",
            "Epoch: [067][00002/00008]\tTime 0.60 (0.60)\tLoss 0.10 (0.10)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.07 (0.07)\n",
            "Epoch: [067][00004/00008]\tTime 0.18 (0.39)\tLoss 0.07 (0.09)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.06 (0.06)\n",
            "Epoch: [067][00006/00008]\tTime 0.18 (0.32)\tLoss 0.07 (0.08)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.06)\n",
            "[Train]: Epoch 67 finished with lr=0.00005314\n",
            "\n",
            "\n",
            "[Train]: Epoch 68 started\n",
            "Epoch: [068][00002/00008]\tTime 0.64 (0.64)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.05 (0.05)\n",
            "Epoch: [068][00004/00008]\tTime 0.25 (0.45)\tLoss 0.05 (0.06)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.04 (0.04)\n",
            "Epoch: [068][00006/00008]\tTime 0.26 (0.38)\tLoss 0.07 (0.06)\n",
            "\t\tcls_loss 0.03 (0.02)\treg_loss 0.05 (0.04)\n",
            "[Train]: Epoch 68 finished with lr=0.00005158\n",
            "\n",
            "\n",
            "[Train]: Epoch 69 started\n",
            "Epoch: [069][00002/00008]\tTime 0.67 (0.67)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [069][00004/00008]\tTime 0.25 (0.46)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "Epoch: [069][00006/00008]\tTime 0.22 (0.38)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 69 finished with lr=0.00005000\n",
            "\n",
            "\n",
            "[Train]: Epoch 70 started\n",
            "Epoch: [070][00002/00008]\tTime 0.60 (0.60)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [070][00004/00008]\tTime 0.18 (0.39)\tLoss 0.08 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "Epoch: [070][00006/00008]\tTime 0.19 (0.32)\tLoss 0.06 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 70 finished with lr=0.00004843\n",
            "\n",
            "\n",
            "[Train]: Epoch 71 started\n",
            "Epoch: [071][00002/00008]\tTime 0.56 (0.56)\tLoss 0.08 (0.08)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.06)\n",
            "Epoch: [071][00004/00008]\tTime 0.20 (0.38)\tLoss 0.06 (0.07)\n",
            "\t\tcls_loss 0.01 (0.02)\treg_loss 0.05 (0.05)\n",
            "Epoch: [071][00006/00008]\tTime 0.19 (0.32)\tLoss 0.06 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.05)\n",
            "[Train]: Epoch 71 finished with lr=0.00004687\n",
            "\n",
            "\n",
            "[Train]: Epoch 72 started\n",
            "Epoch: [072][00002/00008]\tTime 0.45 (0.45)\tLoss 0.12 (0.12)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.09 (0.09)\n",
            "Epoch: [072][00004/00008]\tTime 0.19 (0.32)\tLoss 0.06 (0.09)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.07)\n",
            "Epoch: [072][00006/00008]\tTime 0.18 (0.27)\tLoss 0.06 (0.08)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.06)\n",
            "[Train]: Epoch 72 finished with lr=0.00004530\n",
            "\n",
            "\n",
            "[Train]: Epoch 73 started\n",
            "Epoch: [073][00002/00008]\tTime 0.44 (0.44)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [073][00004/00008]\tTime 0.19 (0.31)\tLoss 0.10 (0.08)\n",
            "\t\tcls_loss 0.03 (0.02)\treg_loss 0.07 (0.06)\n",
            "Epoch: [073][00006/00008]\tTime 0.18 (0.27)\tLoss 0.08 (0.08)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.06 (0.06)\n",
            "[Train]: Epoch 73 finished with lr=0.00004374\n",
            "\n",
            "\n",
            "[Train]: Epoch 74 started\n",
            "Epoch: [074][00002/00008]\tTime 0.43 (0.43)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [074][00004/00008]\tTime 0.19 (0.31)\tLoss 0.08 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.06 (0.05)\n",
            "Epoch: [074][00006/00008]\tTime 0.18 (0.27)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "[Train]: Epoch 74 finished with lr=0.00004218\n",
            "\n",
            "\n",
            "[Train]: Epoch 75 started\n",
            "Epoch: [075][00002/00008]\tTime 0.65 (0.65)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [075][00004/00008]\tTime 0.29 (0.47)\tLoss 0.07 (0.06)\n",
            "\t\tcls_loss 0.03 (0.02)\treg_loss 0.05 (0.04)\n",
            "Epoch: [075][00006/00008]\tTime 0.25 (0.40)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 75 finished with lr=0.00004064\n",
            "\n",
            "\n",
            "[Train]: Epoch 76 started\n",
            "Epoch: [076][00002/00008]\tTime 0.59 (0.59)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [076][00004/00008]\tTime 0.23 (0.41)\tLoss 0.07 (0.06)\n",
            "\t\tcls_loss 0.03 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [076][00006/00008]\tTime 0.23 (0.35)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 76 finished with lr=0.00003910\n",
            "\n",
            "\n",
            "[Train]: Epoch 77 started\n",
            "Epoch: [077][00002/00008]\tTime 0.65 (0.65)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [077][00004/00008]\tTime 0.20 (0.42)\tLoss 0.08 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.06 (0.05)\n",
            "Epoch: [077][00006/00008]\tTime 0.18 (0.34)\tLoss 0.08 (0.07)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.05 (0.05)\n",
            "[Train]: Epoch 77 finished with lr=0.00003757\n",
            "\n",
            "\n",
            "[Train]: Epoch 78 started\n",
            "Epoch: [078][00002/00008]\tTime 0.44 (0.44)\tLoss 0.08 (0.08)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.05 (0.05)\n",
            "Epoch: [078][00004/00008]\tTime 0.19 (0.32)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "Epoch: [078][00006/00008]\tTime 0.18 (0.27)\tLoss 0.09 (0.08)\n",
            "\t\tcls_loss 0.04 (0.03)\treg_loss 0.05 (0.05)\n",
            "[Train]: Epoch 78 finished with lr=0.00003606\n",
            "\n",
            "\n",
            "[Train]: Epoch 79 started\n",
            "Epoch: [079][00002/00008]\tTime 0.76 (0.76)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.05 (0.05)\n",
            "Epoch: [079][00004/00008]\tTime 0.18 (0.47)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "Epoch: [079][00006/00008]\tTime 0.21 (0.39)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "[Train]: Epoch 79 finished with lr=0.00003456\n",
            "\n",
            "\n",
            "[Train]: Epoch 80 started\n",
            "Epoch: [080][00002/00008]\tTime 0.63 (0.63)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [080][00004/00008]\tTime 0.19 (0.41)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [080][00006/00008]\tTime 0.19 (0.34)\tLoss 0.05 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.03 (0.04)\n",
            "[Train]: Epoch 80 finished with lr=0.00003307\n",
            "\n",
            "\n",
            "[Train]: Epoch 81 started\n",
            "Epoch: [081][00002/00008]\tTime 0.57 (0.57)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [081][00004/00008]\tTime 0.23 (0.40)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.04)\n",
            "Epoch: [081][00006/00008]\tTime 0.22 (0.34)\tLoss 0.05 (0.06)\n",
            "\t\tcls_loss 0.01 (0.02)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 81 finished with lr=0.00003160\n",
            "\n",
            "\n",
            "[Train]: Epoch 82 started\n",
            "Epoch: [082][00002/00008]\tTime 0.59 (0.59)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [082][00004/00008]\tTime 0.21 (0.40)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [082][00006/00008]\tTime 0.24 (0.35)\tLoss 0.07 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 82 finished with lr=0.00003015\n",
            "\n",
            "\n",
            "[Train]: Epoch 83 started\n",
            "Epoch: [083][00002/00008]\tTime 0.82 (0.82)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "Epoch: [083][00004/00008]\tTime 0.22 (0.52)\tLoss 0.10 (0.08)\n",
            "\t\tcls_loss 0.03 (0.02)\treg_loss 0.07 (0.06)\n",
            "Epoch: [083][00006/00008]\tTime 0.19 (0.41)\tLoss 0.08 (0.08)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.05 (0.06)\n",
            "[Train]: Epoch 83 finished with lr=0.00002872\n",
            "\n",
            "\n",
            "[Train]: Epoch 84 started\n",
            "Epoch: [084][00002/00008]\tTime 0.66 (0.66)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "Epoch: [084][00004/00008]\tTime 0.19 (0.43)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "Epoch: [084][00006/00008]\tTime 0.18 (0.34)\tLoss 0.05 (0.07)\n",
            "\t\tcls_loss 0.01 (0.02)\treg_loss 0.04 (0.05)\n",
            "[Train]: Epoch 84 finished with lr=0.00002731\n",
            "\n",
            "\n",
            "[Train]: Epoch 85 started\n",
            "Epoch: [085][00002/00008]\tTime 0.58 (0.58)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [085][00004/00008]\tTime 0.19 (0.38)\tLoss 0.09 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.06 (0.05)\n",
            "Epoch: [085][00006/00008]\tTime 0.19 (0.32)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "[Train]: Epoch 85 finished with lr=0.00002592\n",
            "\n",
            "\n",
            "[Train]: Epoch 86 started\n",
            "Epoch: [086][00002/00008]\tTime 0.57 (0.57)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [086][00004/00008]\tTime 0.19 (0.38)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "Epoch: [086][00006/00008]\tTime 0.19 (0.31)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "[Train]: Epoch 86 finished with lr=0.00002456\n",
            "\n",
            "\n",
            "[Train]: Epoch 87 started\n",
            "Epoch: [087][00002/00008]\tTime 0.42 (0.42)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.04 (0.04)\n",
            "Epoch: [087][00004/00008]\tTime 0.19 (0.31)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.04 (0.04)\n",
            "Epoch: [087][00006/00008]\tTime 0.18 (0.27)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.02 (0.01)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 87 finished with lr=0.00002322\n",
            "\n",
            "\n",
            "[Train]: Epoch 88 started\n",
            "Epoch: [088][00002/00008]\tTime 0.43 (0.43)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.04 (0.04)\n",
            "Epoch: [088][00004/00008]\tTime 0.26 (0.34)\tLoss 0.07 (0.06)\n",
            "\t\tcls_loss 0.03 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [088][00006/00008]\tTime 0.27 (0.32)\tLoss 0.08 (0.07)\n",
            "\t\tcls_loss 0.03 (0.02)\treg_loss 0.05 (0.05)\n",
            "[Train]: Epoch 88 finished with lr=0.00002190\n",
            "\n",
            "\n",
            "[Train]: Epoch 89 started\n",
            "Epoch: [089][00002/00008]\tTime 0.79 (0.79)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [089][00004/00008]\tTime 0.23 (0.51)\tLoss 0.05 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.03 (0.04)\n",
            "Epoch: [089][00006/00008]\tTime 0.25 (0.42)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 89 finished with lr=0.00002062\n",
            "\n",
            "\n",
            "[Train]: Epoch 90 started\n",
            "Epoch: [090][00002/00008]\tTime 0.66 (0.66)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "Epoch: [090][00004/00008]\tTime 0.19 (0.43)\tLoss 0.05 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.03 (0.04)\n",
            "Epoch: [090][00006/00008]\tTime 0.18 (0.35)\tLoss 0.08 (0.06)\n",
            "\t\tcls_loss 0.03 (0.02)\treg_loss 0.05 (0.04)\n",
            "[Train]: Epoch 90 finished with lr=0.00001936\n",
            "\n",
            "\n",
            "[Train]: Epoch 91 started\n",
            "Epoch: [091][00002/00008]\tTime 0.59 (0.59)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [091][00004/00008]\tTime 0.18 (0.38)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [091][00006/00008]\tTime 0.18 (0.32)\tLoss 0.05 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.03 (0.04)\n",
            "[Train]: Epoch 91 finished with lr=0.00001814\n",
            "\n",
            "\n",
            "[Train]: Epoch 92 started\n",
            "Epoch: [092][00002/00008]\tTime 0.53 (0.53)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [092][00004/00008]\tTime 0.19 (0.36)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [092][00006/00008]\tTime 0.18 (0.30)\tLoss 0.08 (0.06)\n",
            "\t\tcls_loss 0.03 (0.02)\treg_loss 0.05 (0.04)\n",
            "[Train]: Epoch 92 finished with lr=0.00001694\n",
            "\n",
            "\n",
            "[Train]: Epoch 93 started\n",
            "Epoch: [093][00002/00008]\tTime 0.41 (0.41)\tLoss 0.08 (0.08)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.06 (0.06)\n",
            "Epoch: [093][00004/00008]\tTime 0.18 (0.30)\tLoss 0.06 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.03 (0.04)\n",
            "Epoch: [093][00006/00008]\tTime 0.19 (0.26)\tLoss 0.06 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "[Train]: Epoch 93 finished with lr=0.00001578\n",
            "\n",
            "\n",
            "[Train]: Epoch 94 started\n",
            "Epoch: [094][00002/00008]\tTime 0.63 (0.63)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.04 (0.04)\n",
            "Epoch: [094][00004/00008]\tTime 0.18 (0.40)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.02 (0.01)\treg_loss 0.03 (0.04)\n",
            "Epoch: [094][00006/00008]\tTime 0.18 (0.33)\tLoss 0.06 (0.05)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 94 finished with lr=0.00001465\n",
            "\n",
            "\n",
            "[Train]: Epoch 95 started\n",
            "Epoch: [095][00002/00008]\tTime 0.74 (0.74)\tLoss 0.08 (0.08)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.06)\n",
            "Epoch: [095][00004/00008]\tTime 0.27 (0.50)\tLoss 0.07 (0.08)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.04 (0.05)\n",
            "Epoch: [095][00006/00008]\tTime 0.24 (0.42)\tLoss 0.06 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 95 finished with lr=0.00001356\n",
            "\n",
            "\n",
            "[Train]: Epoch 96 started\n",
            "Epoch: [096][00002/00008]\tTime 0.57 (0.57)\tLoss 0.09 (0.09)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.06 (0.06)\n",
            "Epoch: [096][00004/00008]\tTime 0.24 (0.40)\tLoss 0.04 (0.06)\n",
            "\t\tcls_loss 0.01 (0.02)\treg_loss 0.03 (0.04)\n",
            "Epoch: [096][00006/00008]\tTime 0.23 (0.35)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 96 finished with lr=0.00001250\n",
            "\n",
            "\n",
            "[Train]: Epoch 97 started\n",
            "Epoch: [097][00002/00008]\tTime 0.63 (0.63)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.06 (0.06)\n",
            "Epoch: [097][00004/00008]\tTime 0.18 (0.40)\tLoss 0.05 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.03 (0.04)\n",
            "Epoch: [097][00006/00008]\tTime 0.19 (0.33)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.03 (0.02)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 97 finished with lr=0.00001148\n",
            "\n",
            "\n",
            "[Train]: Epoch 98 started\n",
            "Epoch: [098][00002/00008]\tTime 0.38 (0.38)\tLoss 0.04 (0.04)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.03 (0.03)\n",
            "Epoch: [098][00004/00008]\tTime 0.20 (0.29)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.04 (0.03)\n",
            "Epoch: [098][00006/00008]\tTime 0.19 (0.26)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.04 (0.03)\n",
            "[Train]: Epoch 98 finished with lr=0.00001050\n",
            "\n",
            "\n",
            "[Train]: Epoch 99 started\n",
            "Epoch: [099][00002/00008]\tTime 0.43 (0.43)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.03 (0.03)\n",
            "Epoch: [099][00004/00008]\tTime 0.18 (0.31)\tLoss 0.06 (0.05)\n",
            "\t\tcls_loss 0.03 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [099][00006/00008]\tTime 0.19 (0.27)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 99 finished with lr=0.00000956\n",
            "\n",
            "\n",
            "[Train]: Epoch 100 started\n",
            "Epoch: [100][00002/00008]\tTime 0.66 (0.66)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.04 (0.04)\n",
            "Epoch: [100][00004/00008]\tTime 0.18 (0.42)\tLoss 0.06 (0.05)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [100][00006/00008]\tTime 0.19 (0.34)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 100 finished with lr=0.00000866\n",
            "\n",
            "\n",
            "[Train]: Epoch 101 started\n",
            "Epoch: [101][00002/00008]\tTime 0.57 (0.57)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "Epoch: [101][00004/00008]\tTime 0.19 (0.38)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.03 (0.02)\treg_loss 0.04 (0.05)\n",
            "Epoch: [101][00006/00008]\tTime 0.18 (0.31)\tLoss 0.05 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 101 finished with lr=0.00000779\n",
            "\n",
            "\n",
            "[Train]: Epoch 102 started\n",
            "Epoch: [102][00002/00008]\tTime 0.65 (0.65)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.04 (0.04)\n",
            "Epoch: [102][00004/00008]\tTime 0.26 (0.45)\tLoss 0.07 (0.06)\n",
            "\t\tcls_loss 0.03 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [102][00006/00008]\tTime 0.22 (0.38)\tLoss 0.08 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.06 (0.05)\n",
            "[Train]: Epoch 102 finished with lr=0.00000697\n",
            "\n",
            "\n",
            "[Train]: Epoch 103 started\n",
            "Epoch: [103][00002/00008]\tTime 0.73 (0.73)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.05)\n",
            "Epoch: [103][00004/00008]\tTime 0.24 (0.49)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [103][00006/00008]\tTime 0.23 (0.40)\tLoss 0.04 (0.06)\n",
            "\t\tcls_loss 0.01 (0.02)\treg_loss 0.03 (0.04)\n",
            "[Train]: Epoch 103 finished with lr=0.00000619\n",
            "\n",
            "\n",
            "[Train]: Epoch 104 started\n",
            "Epoch: [104][00002/00008]\tTime 0.74 (0.74)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.04 (0.04)\n",
            "Epoch: [104][00004/00008]\tTime 0.18 (0.46)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.03 (0.04)\n",
            "Epoch: [104][00006/00008]\tTime 0.19 (0.37)\tLoss 0.04 (0.05)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.03 (0.04)\n",
            "[Train]: Epoch 104 finished with lr=0.00000546\n",
            "\n",
            "\n",
            "[Train]: Epoch 105 started\n",
            "Epoch: [105][00002/00008]\tTime 0.60 (0.60)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.04 (0.04)\n",
            "Epoch: [105][00004/00008]\tTime 0.19 (0.39)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.03 (0.03)\n",
            "Epoch: [105][00006/00008]\tTime 0.19 (0.32)\tLoss 0.06 (0.05)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 105 finished with lr=0.00000477\n",
            "\n",
            "\n",
            "[Train]: Epoch 106 started\n",
            "Epoch: [106][00002/00008]\tTime 0.43 (0.43)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [106][00004/00008]\tTime 0.19 (0.31)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [106][00006/00008]\tTime 0.19 (0.27)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 106 finished with lr=0.00000412\n",
            "\n",
            "\n",
            "[Train]: Epoch 107 started\n",
            "Epoch: [107][00002/00008]\tTime 0.60 (0.60)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.04 (0.04)\n",
            "Epoch: [107][00004/00008]\tTime 0.18 (0.39)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.03 (0.04)\n",
            "Epoch: [107][00006/00008]\tTime 0.19 (0.32)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.03 (0.03)\n",
            "[Train]: Epoch 107 finished with lr=0.00000352\n",
            "\n",
            "\n",
            "[Train]: Epoch 108 started\n",
            "Epoch: [108][00002/00008]\tTime 0.44 (0.44)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [108][00004/00008]\tTime 0.18 (0.31)\tLoss 0.04 (0.05)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.03 (0.04)\n",
            "Epoch: [108][00006/00008]\tTime 0.19 (0.27)\tLoss 0.07 (0.06)\n",
            "\t\tcls_loss 0.03 (0.02)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 108 finished with lr=0.00000297\n",
            "\n",
            "\n",
            "[Train]: Epoch 109 started\n",
            "Epoch: [109][00002/00008]\tTime 0.74 (0.74)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.03 (0.03)\n",
            "Epoch: [109][00004/00008]\tTime 0.22 (0.48)\tLoss 0.04 (0.05)\n",
            "\t\tcls_loss 0.01 (0.02)\treg_loss 0.03 (0.03)\n",
            "Epoch: [109][00006/00008]\tTime 0.21 (0.39)\tLoss 0.08 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.04)\n",
            "[Train]: Epoch 109 finished with lr=0.00000246\n",
            "\n",
            "\n",
            "[Train]: Epoch 110 started\n",
            "Epoch: [110][00002/00008]\tTime 0.72 (0.72)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.04 (0.04)\n",
            "Epoch: [110][00004/00008]\tTime 0.23 (0.47)\tLoss 0.05 (0.06)\n",
            "\t\tcls_loss 0.02 (0.03)\treg_loss 0.03 (0.04)\n",
            "Epoch: [110][00006/00008]\tTime 0.27 (0.41)\tLoss 0.04 (0.06)\n",
            "\t\tcls_loss 0.01 (0.02)\treg_loss 0.03 (0.03)\n",
            "[Train]: Epoch 110 finished with lr=0.00000200\n",
            "\n",
            "\n",
            "[Train]: Epoch 111 started\n",
            "Epoch: [111][00002/00008]\tTime 0.55 (0.55)\tLoss 0.04 (0.04)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.03 (0.03)\n",
            "Epoch: [111][00004/00008]\tTime 0.21 (0.38)\tLoss 0.07 (0.06)\n",
            "\t\tcls_loss 0.03 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [111][00006/00008]\tTime 0.18 (0.31)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 111 finished with lr=0.00000158\n",
            "\n",
            "\n",
            "[Train]: Epoch 112 started\n",
            "Epoch: [112][00002/00008]\tTime 0.58 (0.58)\tLoss 0.07 (0.07)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.04 (0.04)\n",
            "Epoch: [112][00004/00008]\tTime 0.18 (0.38)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [112][00006/00008]\tTime 0.18 (0.32)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 112 finished with lr=0.00000121\n",
            "\n",
            "\n",
            "[Train]: Epoch 113 started\n",
            "Epoch: [113][00002/00008]\tTime 0.58 (0.58)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.04 (0.04)\n",
            "Epoch: [113][00004/00008]\tTime 0.18 (0.38)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [113][00006/00008]\tTime 0.19 (0.32)\tLoss 0.07 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.04)\n",
            "[Train]: Epoch 113 finished with lr=0.00000090\n",
            "\n",
            "\n",
            "[Train]: Epoch 114 started\n",
            "Epoch: [114][00002/00008]\tTime 0.55 (0.55)\tLoss 0.04 (0.04)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.03 (0.03)\n",
            "Epoch: [114][00004/00008]\tTime 0.27 (0.41)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.03 (0.03)\n",
            "Epoch: [114][00006/00008]\tTime 0.19 (0.34)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.03 (0.03)\n",
            "[Train]: Epoch 114 finished with lr=0.00000063\n",
            "\n",
            "\n",
            "[Train]: Epoch 115 started\n",
            "Epoch: [115][00002/00008]\tTime 0.63 (0.63)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "Epoch: [115][00004/00008]\tTime 0.33 (0.48)\tLoss 0.08 (0.07)\n",
            "\t\tcls_loss 0.03 (0.02)\treg_loss 0.05 (0.04)\n",
            "Epoch: [115][00006/00008]\tTime 0.21 (0.39)\tLoss 0.05 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.03 (0.04)\n",
            "[Train]: Epoch 115 finished with lr=0.00000040\n",
            "\n",
            "\n",
            "[Train]: Epoch 116 started\n",
            "Epoch: [116][00002/00008]\tTime 0.73 (0.73)\tLoss 0.04 (0.04)\n",
            "\t\tcls_loss 0.01 (0.01)\treg_loss 0.03 (0.03)\n",
            "Epoch: [116][00004/00008]\tTime 0.24 (0.48)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.03 (0.03)\n",
            "Epoch: [116][00006/00008]\tTime 0.22 (0.40)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.01 (0.02)\treg_loss 0.04 (0.03)\n",
            "[Train]: Epoch 116 finished with lr=0.00000023\n",
            "\n",
            "\n",
            "[Train]: Epoch 117 started\n",
            "Epoch: [117][00002/00008]\tTime 0.65 (0.65)\tLoss 0.06 (0.06)\n",
            "\t\tcls_loss 0.03 (0.03)\treg_loss 0.04 (0.04)\n",
            "Epoch: [117][00004/00008]\tTime 0.21 (0.43)\tLoss 0.04 (0.05)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.03 (0.03)\n",
            "Epoch: [117][00006/00008]\tTime 0.19 (0.35)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.01 (0.02)\treg_loss 0.03 (0.03)\n",
            "[Train]: Epoch 117 finished with lr=0.00000011\n",
            "\n",
            "\n",
            "[Train]: Epoch 118 started\n",
            "Epoch: [118][00002/00008]\tTime 0.40 (0.40)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.03 (0.03)\n",
            "Epoch: [118][00004/00008]\tTime 0.20 (0.30)\tLoss 0.07 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.05 (0.04)\n",
            "Epoch: [118][00006/00008]\tTime 0.18 (0.26)\tLoss 0.05 (0.06)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 118 finished with lr=0.00000003\n",
            "\n",
            "\n",
            "[Train]: Epoch 119 started\n",
            "Epoch: [119][00002/00008]\tTime 0.49 (0.49)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.03 (0.03)\n",
            "Epoch: [119][00004/00008]\tTime 0.27 (0.38)\tLoss 0.05 (0.05)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.03)\n",
            "Epoch: [119][00006/00008]\tTime 0.23 (0.33)\tLoss 0.06 (0.05)\n",
            "\t\tcls_loss 0.02 (0.02)\treg_loss 0.04 (0.04)\n",
            "[Train]: Epoch 119 finished with lr=0.00000001\n",
            "\n",
            "All done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logdir = \"/content/drive/MyDrive/mRI/action_localization/ckpt/rgb_s1_p1_exp/logs\""
      ],
      "metadata": {
        "id": "oTXnry1d69xh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard --logdir=logdir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "posvTjVg9fgw",
        "outputId": "5114c391-e703-445e-b9ce-07511b136106"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorboard --logdir=logdir'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-c1fa82911be6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tensorboard --logdir=logdir'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-57>\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missing module name.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'already loaded'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard --logdir=logdir'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/MyDrive/mRI/action_localization/eval.py\" \"/content/drive/MyDrive/mRI/action_localization/exp_configs/rgb_s1_p1.yaml\" \"/content/drive/MyDrive/mRI/action_localization/ckpt/rgb_s1_p1_exp\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFuYIwjn9hyy",
        "outputId": "d814102d-9f20-4c06-e5c0-1cbf86b476c5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/mRI/action_localization/eval.py\", line 120, in <module>\n",
            "    main(args)\n",
            "  File \"/content/drive/MyDrive/mRI/action_localization/eval.py\", line 36, in main\n",
            "    ckpt_file = ckpt_file_list[-1]\n",
            "IndexError: list index out of range\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iwEcuTT3-Kyq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}